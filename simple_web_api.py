"""ê°„ë‹¨í•œ ì›¹ API ì„œë²„ - í…ŒìŠ¤íŠ¸ìš©"""

import os
import logging
from fastapi import FastAPI, HTTPException, Request, Depends, Header
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
import json
import asyncio
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Supabase í´ë¼ì´ì–¸íŠ¸
from supabase import create_client, Client

# Yahoo Finance í†µí•©
from src.tools.yahoo_finance import yahoo_analyzer

# RAG ì‹œìŠ¤í…œ í†µí•© - Supabase ê¸°ë°˜
from src.tools.supabase_rag import SupabaseRAG
from src.tools.rag_portfolio_advisor import get_rag_based_portfolio

# ìºì‹œ ë§¤ë‹ˆì € í†µí•© - 1ì‹œê°„ TTL ìºì‹±
from src.tools.cache_manager import cache_manager

# Supabase RAG ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
supabase_rag = SupabaseRAG()

# ê¸°ì¡´ API í˜¸í™˜ì„ ìœ„í•œ wrapper í•¨ìˆ˜
def get_relevant_insights(query: str, top_k: int = 3):
    """Supabase RAGì—ì„œ ê´€ë ¨ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰ (ë²¡í„° + í…ìŠ¤íŠ¸ í•˜ì´ë¸Œë¦¬ë“œ)"""
    results = supabase_rag.search_similar(query, top_k=top_k, use_text_search=True)
    return results if results else []

def format_insights_for_llm(insights):
    """ì¸ì‚¬ì´íŠ¸ë¥¼ LLM ì¹œí™”ì  í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
    if not insights:
        return ""

    formatted = "\n\nğŸ“Š **íˆ¬ì ì¸ì‚¬ì´íŠ¸ (ë¸”ë¡œê·¸ ë¶„ì„)**:\n"
    for i, insight in enumerate(insights, 1):
        formatted += f"\n{i}. **{insight['title']}** (ìœ ì‚¬ë„: {insight['similarity']:.0%})\n"
        formatted += f"   - ì„¹í„°: {insight['sector']}\n"
        formatted += f"   - ê°ì„±: {insight['sentiment']}\n"
        formatted += f"   - í‚¤ì›Œë“œ: {', '.join(insight['keywords'][:5])}\n"
        formatted += f"   - ìš”ì•½: {insight['content'][:150]}...\n"

    return formatted

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
SUPABASE_URL = os.getenv("SUPABASE_URL", "http://localhost:8000")
SUPABASE_KEY = os.getenv("SUPABASE_KEY", os.getenv("ANON_KEY", ""))
SUPABASE_SERVICE_KEY = os.getenv("SERVICE_ROLE_KEY", "")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
supabase_admin: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY) if SUPABASE_SERVICE_KEY else None

app = FastAPI(title="AI í—¤ì§€í€ë“œ ì‹œìŠ¤í…œ")

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="web"), name="static")

# ê±°ë˜ íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ ì €ì¥ - ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” DB ì‚¬ìš©)
trade_history = []

# ê°„ë‹¨í•œ ì¸ì¦ ì‹œìŠ¤í…œ (ë ˆê±°ì‹œ - Supabase Authë¡œ ëŒ€ì²´ ì˜ˆì •)
USERNAME = os.getenv("WEB_USERNAME", "admin")
PASSWORD = os.getenv("WEB_PASSWORD", "hedge2024!")

# JWT ì¸ì¦ ë¯¸ë“¤ì›¨ì–´
async def verify_token(authorization: Optional[str] = Header(None)) -> Dict[str, Any]:
    """JWT í† í° ê²€ì¦ ë° ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ"""
    if not authorization:
        raise HTTPException(status_code=401, detail="ì¸ì¦ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤")

    try:
        # "Bearer <token>" í˜•ì‹ì—ì„œ í† í° ì¶”ì¶œ
        scheme, token = authorization.split()
        if scheme.lower() != "bearer":
            raise HTTPException(status_code=401, detail="ì˜ëª»ëœ ì¸ì¦ ë°©ì‹ì…ë‹ˆë‹¤")

        # Supabaseë¥¼ í†µí•œ í† í° ê²€ì¦
        user = supabase.auth.get_user(token)

        if not user or not user.user:
            raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ í† í°ì…ë‹ˆë‹¤")

        return {
            "user_id": user.user.id,
            "email": user.user.email,
            "user": user.user
        }

    except ValueError:
        raise HTTPException(status_code=401, detail="ì˜ëª»ëœ í† í° í˜•ì‹ì…ë‹ˆë‹¤")
    except Exception as e:
        print(f"í† í° ê²€ì¦ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=401, detail=f"í† í° ê²€ì¦ ì‹¤íŒ¨: {str(e)}")

class LoginRequest(BaseModel):
    username: str
    password: str

class AuthRequest(BaseModel):
    email: str
    password: str

class TradeRequest(BaseModel):
    symbol: str
    action: str
    quantity: int

@app.get("/", response_class=HTMLResponse)
async def root():
    """ë©”ì¸ í˜ì´ì§€ (í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œ ì¸ì¦ ì²´í¬)"""
    with open("web/index.html", "r", encoding="utf-8") as f:
        return f.read()

@app.get("/login", response_class=HTMLResponse)
async def login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€"""
    with open("web/login.html", "r", encoding="utf-8") as f:
        return f.read()

@app.post("/api/auth/signup")
async def auth_signup(request: AuthRequest):
    """Supabase Auth íšŒì›ê°€ì… - SERVICE_ROLE_KEY ì‚¬ìš©í•˜ì—¬ ì´ë©”ì¼ í™•ì¸ ìš°íšŒ"""
    try:
        if not supabase_admin:
            raise HTTPException(status_code=500, detail="ê´€ë¦¬ì ê¶Œí•œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # Admin í´ë¼ì´ì–¸íŠ¸ë¡œ ì‚¬ìš©ì ìƒì„± (ì´ë©”ì¼ í™•ì¸ ìš°íšŒ)
        response = supabase_admin.auth.admin.create_user({
            "email": request.email,
            "password": request.password,
            "email_confirm": True  # ì´ë©”ì¼ í™•ì¸ ìë™ ì²˜ë¦¬
        })

        if response.user:
            # ìƒì„±ëœ ì‚¬ìš©ìë¡œ ë¡œê·¸ì¸í•˜ì—¬ ì„¸ì…˜ í† í° ë°œê¸‰
            login_response = supabase.auth.sign_in_with_password({
                "email": request.email,
                "password": request.password
            })

            return {
                "success": True,
                "user": {
                    "id": response.user.id,
                    "email": response.user.email
                },
                "session": {
                    "access_token": login_response.session.access_token if login_response.session else None,
                    "refresh_token": login_response.session.refresh_token if login_response.session else None
                } if login_response.session else None,
                "message": "íšŒì›ê°€ì… ì„±ê³µ"
            }
        else:
            raise HTTPException(status_code=400, detail="íšŒì›ê°€ì… ì‹¤íŒ¨")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"íšŒì›ê°€ì… ì‹¤íŒ¨: {str(e)}")

@app.post("/api/auth/login")
async def auth_login(request: AuthRequest):
    """Supabase Auth ë¡œê·¸ì¸"""
    try:
        response = supabase.auth.sign_in_with_password({
            "email": request.email,
            "password": request.password
        })

        if response.user and response.session:
            return {
                "success": True,
                "user": {
                    "id": response.user.id,
                    "email": response.user.email
                },
                "session": {
                    "access_token": response.session.access_token,
                    "refresh_token": response.session.refresh_token
                },
                "message": "ë¡œê·¸ì¸ ì„±ê³µ"
            }
        else:
            raise HTTPException(status_code=401, detail="ë¡œê·¸ì¸ ì‹¤íŒ¨")
    except Exception as e:
        raise HTTPException(status_code=401, detail=f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/login")
async def login(request: LoginRequest):
    """ë¡œê·¸ì¸ (ë ˆê±°ì‹œ)"""
    if request.username == USERNAME and request.password == PASSWORD:
        return {"success": True, "access_token": "demo-token", "token_type": "bearer"}
    else:
        raise HTTPException(status_code=401, detail="Invalid credentials")

@app.get("/api/status")
async def get_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ"""
    return {
        "status": "running",
        "mode": "paper_trading",
        "account": {
            "balance": 100000.0,
            "buying_power": 95000.0,
            "positions": []
        }
    }

@app.get("/api/portfolio")
async def get_portfolio(current_user: Dict[str, Any] = Depends(verify_token)):
    """í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ (ì¸ì¦ í•„ìš”)"""
    # ì‚¬ìš©ìë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ (í–¥í›„ êµ¬í˜„)
    user_id = current_user["user_id"]

    return {
        "user_id": user_id,
        "total_value": 100000.0,
        "cash": 95000.0,
        "positions": [
            {
                "symbol": "AAPL",
                "quantity": 10,
                "avg_price": 150.0,
                "current_price": 155.0,
                "market_value": 1550.0,
                "unrealized_pnl": 50.0
            }
        ]
    }

@app.post("/api/analyze")
async def analyze_stock(request: Dict[str, Any] = None):
    """ì£¼ì‹ ë¶„ì„ - ê°œë³„ ì£¼ì‹ ë˜ëŠ” ìë™ ìŠ¤í¬ë¦¬ë‹ (1ì‹œê°„ ìºì‹±)"""
    if request is None:
        request = {}

    symbol = request.get("symbol", "")

    if symbol:
        # ìºì‹œ ì¡°íšŒ (symbolë³„ë¡œ 1ì‹œê°„ ìºì‹±)
        cached = cache_manager.get_cached("analyze", params={"symbol": symbol}, ttl_seconds=3600)
        if cached:
            logger.info(f"âœ… ìºì‹œì—ì„œ {symbol} ë¶„ì„ ë°˜í™˜")
            return cached

        # ê°œë³„ ì£¼ì‹ ë¶„ì„ - yahoo_finance.pyì˜ ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš©
        try:
            import yfinance as yf
            from src.tools.yahoo_finance import yahoo_analyzer

            logger.info(f"ğŸ”„ {symbol} ë¶„ì„ ìƒˆë¡œ ê³„ì‚° ì¤‘...")

            # í•œêµ­ ì¢…ëª© ì½”ë“œ ë³€í™˜ (6ìë¦¬ ìˆ«ìë©´ .KS ì¶”ê°€)
            yahoo_symbol = symbol
            if symbol.isdigit() and len(symbol) == 6:
                yahoo_symbol = f"{symbol}.KS"

            # ê³ ê¸‰ metrics ê³„ì‚° (ìºì‹± ë° ë³‘ë ¬ ì²˜ë¦¬ ì ìš©)
            metrics = yahoo_analyzer.calculate_financial_metrics(yahoo_symbol)

            if not metrics:
                raise Exception("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # íšŒì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            ticker = yf.Ticker(yahoo_symbol)
            info = ticker.info
            company_name = info.get('longName', symbol)

            # RAG ì¸ì‚¬ì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
            insights = get_relevant_insights(symbol, top_k=2)

            # ì¶”ì²œ ë¡œì§
            returns_1y = metrics.get('returns_1y', 0)
            recommendation = "ë§¤ìˆ˜" if returns_1y > 10 else "ê´€ë§" if returns_1y > 0 else "ì£¼ì˜"

            # ê¸°ë³¸ ë¶„ì„ ìƒì„± (ì•¼í›„ íŒŒì´ë‚¸ì…œ ë°ì´í„°ë§Œ - ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ì œì™¸)
            analysis = yahoo_analyzer.generate_stock_analysis(yahoo_symbol, metrics)

            result = {
                "success": True,  # success í”Œë˜ê·¸ ì¶”ê°€
                "symbol": symbol,
                "company_name": company_name,
                "recommendation": recommendation,
                "confidence": 0.85,
                "analysis": analysis.strip(),
                "blog_insights": insights if insights else [],  # ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ë³„ë„ í•„ë“œ
                "metrics": metrics  # ëª¨ë“  metrics í¬í•¨ (returns_1m, returns_3m, volatility ë“±)
            }

            # ìºì‹œ ì €ì¥ (1ì‹œê°„)
            cache_manager.set_cached("analyze", result, params={"symbol": symbol}, ttl_seconds=3600)
            logger.info(f"ğŸ’¾ {symbol} ë¶„ì„ ìºì‹œ ì €ì¥ ì™„ë£Œ")

            return result
        except Exception as e:
            return {
                "symbol": symbol,
                "company_name": symbol,
                "error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "analysis": f"{symbol} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "metrics": {}
            }
    else:
        # ìë™ ì£¼ì‹ ìŠ¤í¬ë¦¬ë‹ (ìºì‹±ëœ top-stocks í™œìš©)
        try:
            from src.tools.yahoo_finance import get_top_stocks
            top_stocks = get_top_stocks(5)
            return {
                "auto_screening": True,
                "top_stocks": top_stocks,
                "message": "AIê°€ ì„ ë³„í•œ ìƒìœ„ 5ê°œ ì¶”ì²œ ì£¼ì‹ì…ë‹ˆë‹¤."
            }
        except Exception as e:
            return {
                "auto_screening": False,
                "error": str(e),
                "message": f"ìë™ ìŠ¤í¬ë¦¬ë‹ ì‹¤íŒ¨: {str(e)}"
            }

@app.get("/api/top-stocks")
async def get_top_stocks_api():
    """ìƒìœ„ ì¶”ì²œ ì£¼ì‹ ì¡°íšŒ (1ì‹œê°„ ìºì‹±)"""
    # ìºì‹œ ì¡°íšŒ (1ì‹œê°„ TTL)
    cached = cache_manager.get_cached("top-stocks", ttl_seconds=3600)
    if cached:
        logger.info("âœ… ìºì‹œì—ì„œ AI ì¶”ì²œ ì¢…ëª© ë°˜í™˜")
        return cached

    try:
        from src.tools.yahoo_finance import get_top_stocks
        logger.info("ğŸ”„ AI ì¶”ì²œ ì¢…ëª© ìƒˆë¡œ ê³„ì‚° ì¤‘...")
        top_stocks = get_top_stocks(5)

        result = {
            "success": True,
            "stocks": top_stocks,
            "generated_at": datetime.now().isoformat(),
            "message": "Yahoo Finance ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ AI ì¶”ì²œ ì£¼ì‹ì…ë‹ˆë‹¤."
        }

        # ìºì‹œ ì €ì¥ (1ì‹œê°„)
        cache_manager.set_cached("top-stocks", result, ttl_seconds=3600)
        logger.info("ğŸ’¾ AI ì¶”ì²œ ì¢…ëª© ìºì‹œ ì €ì¥ ì™„ë£Œ")

        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ì¶”ì²œ ì£¼ì‹ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        }

@app.post("/api/trade")
async def execute_trade(request: TradeRequest, current_user: Dict[str, Any] = Depends(verify_token)):
    """ê±°ë˜ ì‹¤í–‰ (ì¸ì¦ í•„ìš”)"""
    user_id = current_user["user_id"]

    return {
        "success": True,
        "user_id": user_id,
        "order_id": "demo-order-123",
        "message": f"{request.action} {request.quantity} shares of {request.symbol} - Paper Trading Mode",
        "status": "filled"
    }

@app.get("/api/trade-history")
async def get_trade_history():
    """ê±°ë˜ ë‚´ì—­ (ê¸°ì¡´)"""
    return {
        "trades": [
            {
                "id": "trade-001",
                "symbol": "AAPL",
                "action": "BUY",
                "quantity": 10,
                "price": 150.0,
                "timestamp": "2024-01-01T10:00:00Z",
                "status": "filled"
            }
        ]
    }

@app.get("/api/alerts")
async def get_alerts():
    """ì•Œë¦¼ ëª©ë¡"""
    return {
        "alerts": [
            {
                "type": "info",
                "message": "AI í—¤ì§€í€ë“œ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "timestamp": "2024-01-01T09:00:00Z"
            },
            {
                "type": "warning",
                "message": "í˜„ì¬ í˜ì´í¼ íŠ¸ë ˆì´ë”© ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
                "timestamp": "2024-01-01T09:01:00Z"
            }
        ]
    }

@app.post("/api/portfolio-suggestion")
async def get_portfolio_suggestion(request: Dict[str, Any] = None):
    """AI ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°íˆ¬ì ì œì•ˆ (1ì‹œê°„ ìºì‹±)"""
    if request is None:
        request = {}

    # íˆ¬ì ê¸ˆì•¡ (ê¸°ë³¸ê°’: 1ì–µì›)
    total_investment = request.get("total_investment", 100000000)

    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ AI ì¶”ì²œ ì¢…ëª© ì‚¬ìš©)
    stocks_from_request = request.get("stocks", None)

    # ìºì‹œ ì¡°íšŒ (total_investment + stocksë¡œ 1ì‹œê°„ ìºì‹±)
    stocks_key = ",".join(stocks_from_request) if stocks_from_request else "auto"
    cache_params = {"total_investment": total_investment, "stocks": stocks_key}
    cached = cache_manager.get_cached("portfolio-suggestion", params=cache_params, ttl_seconds=3600)
    if cached:
        logger.info(f"âœ… ìºì‹œì—ì„œ í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ ë°˜í™˜ (íˆ¬ìê¸ˆì•¡: {total_investment:,}ì›)")
        return cached

    try:
        from src.tools.yahoo_finance import get_top_stocks
        import yfinance as yf
        from src.tools.yahoo_finance import yahoo_analyzer

        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê²°ì •
        if stocks_from_request and len(stocks_from_request) > 0:
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ëœ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© (ìƒìœ„ 5ê°œë§Œ)
            # ì²« 5ê°œë§Œ ì„ íƒ
            selected_symbols = stocks_from_request[:5]

            top_stocks = []
            for stock_symbol in selected_symbols:
                try:
                    # í•œêµ­ ì¢…ëª© ì½”ë“œ ë³€í™˜
                    yahoo_symbol = stock_symbol
                    if stock_symbol.isdigit() and len(stock_symbol) == 6:
                        yahoo_symbol = f"{stock_symbol}.KS"

                    # metrics ê³„ì‚°
                    metrics = yahoo_analyzer.calculate_financial_metrics(yahoo_symbol)
                    if metrics:
                        ticker = yf.Ticker(yahoo_symbol)
                        info = ticker.info

                        top_stocks.append({
                            'ticker': stock_symbol,
                            'current_price': metrics.get('current_price', 0),
                            'score': metrics.get('score', 70),  # ê¸°ë³¸ ì ìˆ˜
                            'returns_1y': metrics.get('returns_1y', 0),
                            'volatility': metrics.get('volatility', 20),
                            'pe_ratio': metrics.get('pe_ratio', 'N/A')
                        })
                except Exception as e:
                    print(f"ì¢…ëª© {stock_symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
        else:
            # ê¸°ì¡´ ë°©ì‹: AI ì¶”ì²œ ìƒìœ„ 5ê°œ ì¢…ëª© ì‚¬ìš© (10ê°œì—ì„œ 5ê°œë¡œ ì¶•ì†Œ)
            top_stocks = get_top_stocks(5)

        if not top_stocks:
            return {
                "success": False,
                "message": "ì¶”ì²œ ì¢…ëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        # âœ¨ RAG ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ê²°ì • (ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ í™œìš©)
        logger.info("\nğŸ¤– RAG ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ ì‹œì‘...")
        rag_result = get_rag_based_portfolio(top_stocks, total_investment)

        portfolio = rag_result['portfolio']
        market_outlook = rag_result['market_outlook']
        strategy_summary = rag_result['strategy_summary']

        # ë¦¬ìŠ¤í¬ ë¶„ì„
        avg_volatility = sum(p['volatility'] for p in portfolio) / len(portfolio) if portfolio else 0
        avg_returns = sum(p['returns_1y'] for p in portfolio) / len(portfolio) if portfolio else 0

        risk_level = "ë‚®ìŒ" if avg_volatility < 20 else "ë³´í†µ" if avg_volatility < 35 else "ë†’ìŒ"

        logger.info(f"âœ… RAG í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ ì™„ë£Œ: {len(portfolio)}ê°œ ì¢…ëª©\n")

        # í¬íŠ¸í´ë¦¬ì˜¤ì— íšŒì‚¬ ì´ë¦„ ì¶”ê°€
        for stock in portfolio:
            ticker = stock['ticker']
            try:
                yahoo_symbol = ticker
                if ticker.isdigit() and len(ticker) == 6:
                    yahoo_symbol = f"{ticker}.KS"

                ticker_obj = yf.Ticker(yahoo_symbol)
                info = ticker_obj.info
                stock['company_name'] = info.get('longName', ticker)
            except Exception as e:
                stock['company_name'] = ticker
                logger.warning(f"íšŒì‚¬ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {ticker}: {e}")

        # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª©ë“¤ì— ëŒ€í•œ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘
        portfolio_insights = []
        related_stocks_set = set()

        for stock in portfolio:
            ticker = stock['ticker']
            # ê° ì¢…ëª©ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰ (top_k=2)
            insights = get_relevant_insights(ticker, top_k=2)

            for insight in insights:
                portfolio_insights.append({
                    "stock": ticker,
                    "title": insight.get("title", ""),
                    "content": insight.get("content", "")[:200] + "...",  # ìš”ì•½ë§Œ
                    "similarity": insight.get("similarity", 0),
                    "keywords": insight.get("keywords", [])[:5],
                    "sector": insight.get("sector", ""),
                    "sentiment": insight.get("sentiment", ""),
                    "url": insight.get("url", "")
                })

                # ì¸ì‚¬ì´íŠ¸ì˜ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ì¢…ëª© ì°¾ê¸°
                for keyword in insight.get("keywords", [])[:3]:
                    related_stocks_set.add(keyword)

        # ìœ ì‚¬ ì¢…ëª© ì¶”ì²œ (ì‹¤ì œ ê±°ë˜ ê°€ëŠ¥í•œ ì¢…ëª© ì‹¬ë³¼ ë°˜í™˜)
        related_stocks = []

        # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª©ì˜ ì‹œì¥ ê°ì§€ (ì½”ìŠ¤í”¼ vs ë¯¸êµ­)
        portfolio_tickers = [s['ticker'] for s in portfolio]
        is_kospi_portfolio = any(ticker.isdigit() and len(ticker) == 6 for ticker in portfolio_tickers)

        if is_kospi_portfolio:
            # ì½”ìŠ¤í”¼ í¬íŠ¸í´ë¦¬ì˜¤: í•œêµ­ ì£¼ì‹ ì¶”ì²œ
            logger.info("ğŸ‡°ğŸ‡· ì½”ìŠ¤í”¼ í¬íŠ¸í´ë¦¬ì˜¤ ê°ì§€ â†’ í•œêµ­ ì£¼ì‹ ì¶”ì²œ")
            from src.tools.korean_stocks import KoreanStockAnalyzer
            korean_analyzer = KoreanStockAnalyzer()

            # ì½”ìŠ¤í”¼ ìƒìœ„ ì¢…ëª© 20ê°œ ê°€ì ¸ì˜¤ê¸°
            korean_top_stocks = korean_analyzer.get_top_korean_stocks(market="kospi", limit=20)

            # í¬íŠ¸í´ë¦¬ì˜¤ì— ì—†ëŠ” ì¢…ëª©ë“¤ë§Œ í›„ë³´ë¡œ
            candidate_stocks = []
            for k_stock in korean_top_stocks:
                # ticker í˜•ì‹ ë³€í™˜: '005930.KS' â†’ '005930'
                k_ticker = k_stock['ticker'].replace('.KS', '').replace('.KQ', '')
                if k_ticker not in portfolio_tickers:
                    candidate_stocks.append({
                        'ticker': k_ticker,
                        'company_name': k_stock['name'],
                        'current_price': k_stock.get('current_price', 0),
                        'score': 75,  # ê¸°ë³¸ ì ìˆ˜
                        'returns_1y': 0,
                        'volatility': 20,
                        'pe_ratio': k_stock.get('pe_ratio', 'N/A')
                    })
        else:
            # ë¯¸êµ­ í¬íŠ¸í´ë¦¬ì˜¤: ë¯¸êµ­ ì£¼ì‹ ì¶”ì²œ
            logger.info("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ í¬íŠ¸í´ë¦¬ì˜¤ ê°ì§€ â†’ ë¯¸êµ­ ì£¼ì‹ ì¶”ì²œ")
            # AI ì¶”ì²œ ì¢…ëª© ì „ì²´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (top 20ê°œ)
            all_top_stocks = get_top_stocks(20)

            # íšŒì‚¬ ì´ë¦„ ì¶”ê°€
            for stock in all_top_stocks:
                ticker = stock['ticker']
                try:
                    ticker_obj = yf.Ticker(ticker)
                    info = ticker_obj.info
                    stock['company_name'] = info.get('longName', ticker)
                except Exception as e:
                    stock['company_name'] = ticker

            # í¬íŠ¸í´ë¦¬ì˜¤ì— ì—†ëŠ” ì¢…ëª©ë“¤ë§Œ í›„ë³´ë¡œ
            candidate_stocks = [s for s in all_top_stocks if s['ticker'] not in portfolio_tickers]

        if related_stocks_set and candidate_stocks:
            # í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ìœ ì‚¬ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰
            combined_keywords = " ".join(list(related_stocks_set)[:5])
            similar_insights = get_relevant_insights(combined_keywords, top_k=5)

            # ê° í›„ë³´ ì¢…ëª©ì— ëŒ€í•´ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰í•˜ì—¬ ê´€ë ¨ë„ ê³„ì‚°
            stock_scores = {}

            for stock in candidate_stocks[:10]:  # ìƒìœ„ 10ê°œ ì¢…ëª©ë§Œ ê²€ì‚¬
                ticker = stock['ticker']

                # í•´ë‹¹ ì¢…ëª©ì˜ ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰
                stock_insights = get_relevant_insights(ticker, top_k=2)

                # ìœ ì‚¬ ì¸ì‚¬ì´íŠ¸ì™€ì˜ ê´€ë ¨ë„ ê³„ì‚°
                max_similarity = 0
                best_reason = ""

                for stock_insight in stock_insights:
                    # í¬íŠ¸í´ë¦¬ì˜¤ í‚¤ì›Œë“œì™€ ê²¹ì¹˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
                    stock_keywords = set(stock_insight.get("keywords", []))
                    common_keywords = related_stocks_set & stock_keywords

                    if common_keywords or stock_insight.get("similarity", 0) > 0.5:
                        similarity = stock_insight.get("similarity", 0)
                        if similarity > max_similarity:
                            max_similarity = similarity
                            best_reason = f"{stock_insight.get('title', '')[:50]}... ({stock_insight.get('sector', '')})"

                if max_similarity > 0:
                    # candidate_stocksì—ì„œ íšŒì‚¬ ì´ë¦„ ì°¾ê¸°
                    company_name = ticker
                    for candidate in candidate_stocks:
                        if candidate['ticker'] == ticker:
                            company_name = candidate.get('company_name', ticker)
                            break

                    stock_scores[ticker] = {
                        "symbol": ticker,
                        "company_name": company_name,
                        "reason": best_reason,
                        "similarity": max_similarity
                    }

            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 5ê°œ ì„ íƒ
            sorted_stocks = sorted(stock_scores.values(), key=lambda x: x['similarity'], reverse=True)
            related_stocks = sorted_stocks[:5]

        unique_related = related_stocks

        result = {
            "success": True,
            "total_investment": total_investment,
            "portfolio": portfolio,
            "summary": {
                "total_stocks": len(portfolio),
                "total_allocated": sum(p['actual_amount'] for p in portfolio),
                "cash_remaining": total_investment - sum(p['actual_amount'] for p in portfolio),
                "avg_expected_return": round(avg_returns, 2),
                "avg_volatility": round(avg_volatility, 2),
                "risk_level": risk_level
            },
            "market_outlook": market_outlook,  # RAG ê¸°ë°˜ ì‹œì¥ ì „ë§
            "portfolio_insights": portfolio_insights,  # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª©ë³„ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸
            "related_stocks": unique_related,  # ìœ ì‚¬ ì¢…ëª© ì¶”ì²œ
            "recommendation": f"""
ğŸ§  **AI ë¸”ë¡œê·¸ ë¶„ì„ ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤**

ğŸ“Š ì‹œì¥ ì „ë§: {market_outlook}
ğŸ’¡ íˆ¬ì ì „ëµ: {strategy_summary}

ğŸ“ˆ ì˜ˆìƒ ìˆ˜ìµë¥ : {avg_returns:.2f}%
ğŸ“‰ ë³€ë™ì„±: {avg_volatility:.2f}% ({risk_level} ë¦¬ìŠ¤í¬)
ğŸ’° ì´ íˆ¬ì ê¸ˆì•¡: {total_investment:,}ì›

ê° ì¢…ëª©ì˜ ë¹„ì¤‘ì€ ìµœê·¼ ë¸”ë¡œê·¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ AIê°€ ì§€ëŠ¥ì ìœ¼ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.
ìµœì‹  ì‹œì¥ ë™í–¥ê³¼ ê°ì„± ë¶„ì„ì´ ë°˜ì˜ëœ ë°ì´í„° ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ì…ë‹ˆë‹¤.
            """.strip()
        }

        # ìºì‹œ ì €ì¥ (1ì‹œê°„)
        cache_manager.set_cached("portfolio-suggestion", result, params=cache_params, ttl_seconds=3600)
        logger.info(f"ğŸ’¾ í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ ìºì‹œ ì €ì¥ ì™„ë£Œ (íˆ¬ìê¸ˆì•¡: {total_investment:,}ì›, ì¸ì‚¬ì´íŠ¸: {len(portfolio_insights)}ê°œ)")

        return result

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        }

@app.post("/api/portfolio-backtest")
async def backtest_portfolio(request: Dict[str, Any] = None):
    """í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŒ… - ê³¼ê±° ì„±ê³¼ ì‹œë®¬ë ˆì´ì…˜"""
    if request is None:
        request = {}

    portfolio = request.get("portfolio", [])
    months_back = request.get("months_back", 3)

    if not portfolio:
        return {
            "success": False,
            "message": "í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        }

    try:
        import yfinance as yf
        from datetime import datetime, timedelta
        import pandas as pd

        # ë‚ ì§œ ê³„ì‚°
        end_date = datetime.now()
        start_date = end_date - timedelta(days=months_back * 30)

        # ê° ì¢…ëª©ì˜ ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
        daily_returns = {}
        portfolio_values = []
        dates = []

        for stock in portfolio:
            ticker = stock['ticker']
            shares = stock['shares']

            try:
                # í•œêµ­ ì¢…ëª© ì½”ë“œ ë³€í™˜
                yahoo_ticker = ticker
                if ticker.isdigit() and len(ticker) == 6:
                    yahoo_ticker = f"{ticker}.KS"
                    print(f"í•œêµ­ ì¢…ëª© ë³€í™˜: {ticker} â†’ {yahoo_ticker}")

                data = yf.Ticker(yahoo_ticker).history(start=start_date, end=end_date)
                if not data.empty:
                    daily_returns[ticker] = {
                        'prices': data['Close'],
                        'shares': shares
                    }
                    print(f"âœ… {ticker} ë°ì´í„° {len(data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    print(f"âš ï¸ {ticker} ë°ì´í„° ì—†ìŒ")
            except Exception as e:
                print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ {ticker}: {e}")

        if not daily_returns:
            return {
                "success": False,
                "message": "ê³¼ê±° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        # ê³µí†µ ë‚ ì§œ ì°¾ê¸°
        common_dates = None
        for ticker_data in daily_returns.values():
            if common_dates is None:
                common_dates = ticker_data['prices'].index
            else:
                common_dates = common_dates.intersection(ticker_data['prices'].index)

        # í¬íŠ¸í´ë¦¬ì˜¤ ì¼ì¼ ê°€ì¹˜ ê³„ì‚°
        for date in common_dates:
            total_value = sum(
                daily_returns[ticker]['prices'].loc[date] * daily_returns[ticker]['shares']
                for ticker in daily_returns.keys()
            )
            portfolio_values.append(total_value)
            dates.append(date.strftime('%Y-%m-%d'))

        if not portfolio_values:
            return {
                "success": False,
                "message": "í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        # ì´ˆê¸° íˆ¬ìê¸ˆì•¡
        initial_value = portfolio_values[0]
        final_value = portfolio_values[-1]
        total_return = ((final_value - initial_value) / initial_value) * 100

        # ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
        daily_pct_changes = []
        for i in range(1, len(portfolio_values)):
            pct_change = ((portfolio_values[i] - portfolio_values[i-1]) / portfolio_values[i-1]) * 100
            daily_pct_changes.append(pct_change)

        # ë³€ë™ì„± ê³„ì‚° (ì—°í™˜ì‚°)
        volatility = pd.Series(daily_pct_changes).std() * (252 ** 0.5)

        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        peak = portfolio_values[0]
        max_drawdown = 0
        for value in portfolio_values:
            if value > peak:
                peak = value
            drawdown = ((peak - value) / peak) * 100
            if drawdown > max_drawdown:
                max_drawdown = drawdown

        # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° (ë¬´ìœ„í—˜ ìˆ˜ìµë¥  0% ê°€ì •)
        avg_daily_return = pd.Series(daily_pct_changes).mean()
        daily_volatility = pd.Series(daily_pct_changes).std()
        sharpe_ratio = (avg_daily_return / daily_volatility) * (252 ** 0.5) if daily_volatility > 0 else 0

        return {
            "success": True,
            "backtest_period": {
                "start_date": dates[0],
                "end_date": dates[-1],
                "months": months_back
            },
            "performance": {
                "initial_value": round(initial_value, 2),
                "final_value": round(final_value, 2),
                "total_return": round(total_return, 2),
                "volatility": round(volatility, 2),
                "max_drawdown": round(max_drawdown, 2),
                "sharpe_ratio": round(sharpe_ratio, 2)
            },
            "chart_data": {
                "dates": dates,
                "values": [round(v, 2) for v in portfolio_values],
                "returns": [round(((v - initial_value) / initial_value) * 100, 2) for v in portfolio_values]
            },
            "stocks_performance": [
                {
                    "ticker": stock['ticker'],
                    "shares": stock['shares'],
                    "initial_price": round(daily_returns[stock['ticker']]['prices'].iloc[0], 2),
                    "final_price": round(daily_returns[stock['ticker']]['prices'].iloc[-1], 2),
                    "return": round(
                        ((daily_returns[stock['ticker']]['prices'].iloc[-1] -
                          daily_returns[stock['ticker']]['prices'].iloc[0]) /
                         daily_returns[stock['ticker']]['prices'].iloc[0]) * 100, 2
                    )
                }
                for stock in portfolio if stock['ticker'] in daily_returns
            ]
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {str(e)}"
        }

@app.post("/api/save-history")
async def save_history(request: Dict[str, Any], current_user: Dict[str, Any] = Depends(verify_token)):
    """ê±°ë˜ íˆìŠ¤í† ë¦¬ ì €ì¥ (ì¸ì¦ í•„ìš”)"""
    try:
        user_id = current_user["user_id"]
        history_item = {
            "id": len(trade_history) + 1,
            "user_id": user_id,
            "timestamp": datetime.now().isoformat(),
            "type": request.get("type"),  # "screening", "portfolio", "analysis", "trade"
            "data": request.get("data"),
            "result": request.get("result")
        }
        trade_history.append(history_item)
        return {"success": True, "id": history_item["id"]}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/history")
async def get_history(current_user: Dict[str, Any] = Depends(verify_token)):
    """ê±°ë˜ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì¸ì¦ í•„ìš”)"""
    try:
        user_id = current_user["user_id"]
        # ì‚¬ìš©ìë³„ íˆìŠ¤í† ë¦¬ í•„í„°ë§
        user_history = [h for h in trade_history if h.get("user_id") == user_id]
        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_history = sorted(user_history, key=lambda x: x["timestamp"], reverse=True)
        return {
            "success": True,
            "history": sorted_history,
            "total": len(sorted_history)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "history": []
        }

@app.delete("/api/history/{history_id}")
async def delete_history(history_id: int, current_user: Dict[str, Any] = Depends(verify_token)):
    """íŠ¹ì • íˆìŠ¤í† ë¦¬ ì‚­ì œ (ì¸ì¦ í•„ìš”)"""
    global trade_history
    try:
        user_id = current_user["user_id"]
        # ë³¸ì¸ì˜ íˆìŠ¤í† ë¦¬ë§Œ ì‚­ì œ ê°€ëŠ¥
        trade_history = [h for h in trade_history if not (h["id"] == history_id and h.get("user_id") == user_id)]
        return {"success": True, "message": "ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ==================== ê²½ì œì§€í‘œ ë° ë‰´ìŠ¤ API ====================
from typing import Optional

try:
    from src.tools.economic_indicators import get_economic_indicators, get_market_condition
    from src.tools.news_aggregator import get_recent_news, analyze_news_sentiment
    MACRO_FEATURES_AVAILABLE = True
except ImportError:
    MACRO_FEATURES_AVAILABLE = False
    print("âš ï¸ ê²½ì œì§€í‘œ ë° ë‰´ìŠ¤ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. /api/economic-indicators ë“±ì˜ ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


@app.get("/api/economic-indicators")
async def get_economic_indicators_api(country: Optional[str] = None):
    """ê²½ì œì§€í‘œ ì¡°íšŒ
    
    Args:
        country: "US" ë˜ëŠ” "KR" (ì—†ìœ¼ë©´ ì „ì²´)
    """
    if not MACRO_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="ê²½ì œì§€í‘œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        indicators = get_economic_indicators(country)
        return {
            "success": True,
            "count": len(indicators),
            "indicators": [ind.model_dump() for ind in indicators]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²½ì œì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/market-condition")
async def get_market_condition_api():
    """ì‹œì¥ ìƒí™© ë¶„ì„"""
    if not MACRO_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="ì‹œì¥ ìƒí™© ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        condition = get_market_condition()
        return {
            "success": True,
            "condition": condition.model_dump()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‹œì¥ ìƒí™© ë¶„ì„ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/news")
async def get_news_api(
    categories: Optional[str] = None,
    days: int = 7,
    limit: int = 50,
    symbol: Optional[str] = None
):
    """ìµœê·¼ ë‰´ìŠ¤ ì¡°íšŒ (30ë¶„ ìºì‹±)

    Args:
        categories: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "ë¯¸êµ­ê²½ì œ,í•œêµ­ê²½ì œ")
        days: ìµœê·¼ ë©°ì¹ ê°„ì˜ ë‰´ìŠ¤
        limit: ìµœëŒ€ ë‰´ìŠ¤ ê°œìˆ˜
        symbol: ì¢…ëª© ì‹¬ë³¼ (íŠ¹ì • ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰)
    """
    # ìºì‹œ ì¡°íšŒ (symbol/categories + days + limitë¡œ 30ë¶„ ìºì‹±)
    cache_params = {"symbol": symbol or "", "categories": categories or "", "days": days, "limit": limit}
    cached = cache_manager.get_cached("news", params=cache_params, ttl_seconds=1800)
    if cached:
        logger.info(f"âœ… ìºì‹œì—ì„œ ë‰´ìŠ¤ ë°˜í™˜ (symbol={symbol}, categories={categories})")
        return cached

    if not MACRO_FEATURES_AVAILABLE:
        # ì¢…ëª©ë³„ ë‰´ìŠ¤ëŠ” Google News RSS ì‚¬ìš©í•˜ë¯€ë¡œ MACRO_FEATURES ì—†ì–´ë„ ê°€ëŠ¥
        if symbol:
            try:
                import feedparser
                import yfinance as yf

                # íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
                yahoo_symbol = symbol
                if symbol.isdigit() and len(symbol) == 6:
                    yahoo_symbol = f"{symbol}.KS"

                ticker = yf.Ticker(yahoo_symbol)
                info = ticker.info
                company_name = info.get('longName', symbol)

                # Google News RSSë¡œ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
                search_query = f"{symbol}+OR+{company_name.replace(' ', '+')}"
                rss_url = f"https://news.google.com/rss/search?q={search_query}&hl=en-US&gl=US&ceid=US:en"

                feed = feedparser.parse(rss_url)
                news_list = []

                for entry in feed.entries[:limit]:
                    published = entry.get("published_parsed")
                    if published:
                        pub_date = datetime(*published[:6])
                        pub_date_str = pub_date.strftime('%Y-%m-%d %H:%M')
                    else:
                        pub_date_str = datetime.now().strftime('%Y-%m-%d %H:%M')

                    news_list.append({
                        "title": entry.get("title", ""),
                        "description": entry.get("summary", "")[:200],
                        "url": entry.get("link", ""),
                        "source": entry.get("source", {}).get("title", "Google News") if hasattr(entry.get("source", {}), "__getitem__") else "Google News",
                        "published_at": pub_date_str,
                        "category": "stock"
                    })

                result = {
                    "success": True,
                    "count": len(news_list),
                    "news": news_list,
                    "symbol": symbol,
                    "company_name": company_name
                }

                # ìºì‹œ ì €ì¥ (30ë¶„)
                cache_manager.set_cached("news", result, params=cache_params, ttl_seconds=1800)
                logger.info(f"ğŸ’¾ {symbol} ë‰´ìŠ¤ ìºì‹œ ì €ì¥ ì™„ë£Œ")

                return result
            except Exception as e:
                return {
                    "success": False,
                    "error": str(e),
                    "news": [],
                    "message": f"ì¢…ëª© ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
                }
        else:
            raise HTTPException(status_code=503, detail="ë‰´ìŠ¤ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        # ì¢…ëª©ë³„ ë‰´ìŠ¤ ê²€ìƒ‰
        if symbol:
            import feedparser
            import yfinance as yf

            # íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
            yahoo_symbol = symbol
            if symbol.isdigit() and len(symbol) == 6:
                yahoo_symbol = f"{symbol}.KS"

            ticker = yf.Ticker(yahoo_symbol)
            info = ticker.info
            company_name = info.get('longName', symbol)

            # Google News RSSë¡œ ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
            search_query = f"{symbol}+OR+{company_name.replace(' ', '+')}"
            rss_url = f"https://news.google.com/rss/search?q={search_query}&hl=en-US&gl=US&ceid=US:en"

            feed = feedparser.parse(rss_url)
            news_list = []

            for entry in feed.entries[:limit]:
                published = entry.get("published_parsed")
                if published:
                    pub_date = datetime(*published[:6])
                    pub_date_str = pub_date.strftime('%Y-%m-%d %H:%M')
                else:
                    pub_date_str = datetime.now().strftime('%Y-%m-%d %H:%M')

                news_list.append({
                    "title": entry.get("title", ""),
                    "description": entry.get("summary", "")[:200],
                    "url": entry.get("link", ""),
                    "source": entry.get("source", {}).get("title", "Google News") if hasattr(entry.get("source", {}), "__getitem__") else "Google News",
                    "published_at": pub_date_str,
                    "category": "stock"
                })

            result = {
                "success": True,
                "count": len(news_list),
                "news": news_list,
                "symbol": symbol,
                "company_name": company_name
            }

            # ìºì‹œ ì €ì¥ (30ë¶„)
            cache_manager.set_cached("news", result, params=cache_params, ttl_seconds=1800)
            logger.info(f"ğŸ’¾ {symbol} ë‰´ìŠ¤ ìºì‹œ ì €ì¥ ì™„ë£Œ")

            return result

        # ì¼ë°˜ ë‰´ìŠ¤ (ê¸°ì¡´ ë¡œì§)
        category_list = None
        if categories:
            category_list = [c.strip() for c in categories.split(",")]

        news_list = get_recent_news(category_list, days, limit)
        sentiment = analyze_news_sentiment(news_list)

        result = {
            "success": True,
            "count": len(news_list),
            "news": [news.model_dump() for news in news_list],
            "sentiment": sentiment
        }

        # ìºì‹œ ì €ì¥ (30ë¶„)
        cache_manager.set_cached("news", result, params=cache_params, ttl_seconds=1800)
        logger.info(f"ğŸ’¾ ì¼ë°˜ ë‰´ìŠ¤ ìºì‹œ ì €ì¥ ì™„ë£Œ (categories={categories})")

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/api/macro-dashboard")
async def get_macro_dashboard():
    """ê±°ì‹œê²½ì œ ëŒ€ì‹œë³´ë“œ ë°ì´í„° í†µí•© ì¡°íšŒ"""
    if not MACRO_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="ê±°ì‹œê²½ì œ ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    try:
        # ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
        us_indicators = get_economic_indicators("US")
        kr_indicators = get_economic_indicators("KR")
        market_condition = get_market_condition()
        recent_news = get_recent_news(days=3, limit=20)
        news_sentiment = analyze_news_sentiment(recent_news)
        
        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "market_condition": market_condition.model_dump(),
            "indicators": {
                "us": [ind.model_dump() for ind in us_indicators],
                "kr": [ind.model_dump() for ind in kr_indicators]
            },
            "news": {
                "articles": [news.model_dump() for news in recent_news[:10]],
                "sentiment": news_sentiment
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


# ==================== íŠ¸ë Œë”© ì¢…ëª© API ====================
try:
    from src.tools.trending_analyzer import get_trending_stocks, get_trending_analysis
    TRENDING_FEATURES_AVAILABLE = True
except ImportError:
    TRENDING_FEATURES_AVAILABLE = False
    print("âš ï¸ íŠ¸ë Œë”© ì¢…ëª© ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. /api/trending-stocks ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


@app.get("/api/historical-prices")
async def get_historical_prices(symbol: str, period: str = "3m"):
    """ì¢…ëª©ì˜ ê³¼ê±° ê°€ê²© ë°ì´í„° ì¡°íšŒ (1ì‹œê°„ ìºì‹±)

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼
        period: ê¸°ê°„ (1m, 3m, 6m, 1y)

    Returns:
        ë‚ ì§œë³„ ê°€ê²© ë°ì´í„°
    """
    # ìºì‹œ ì¡°íšŒ (symbol + periodë¡œ 1ì‹œê°„ ìºì‹±)
    cached = cache_manager.get_cached("historical-prices", params={"symbol": symbol, "period": period}, ttl_seconds=3600)
    if cached:
        logger.info(f"âœ… ìºì‹œì—ì„œ {symbol} ({period}) ê°€ê²© ë°ì´í„° ë°˜í™˜")
        return cached

    try:
        import yfinance as yf
        from datetime import datetime, timedelta

        logger.info(f"ğŸ”„ {symbol} ({period}) ê°€ê²© ë°ì´í„° ìƒˆë¡œ ê³„ì‚° ì¤‘...")

        # í•œêµ­ ì¢…ëª© ì½”ë“œ ë³€í™˜
        yahoo_symbol = symbol
        if symbol.isdigit() and len(symbol) == 6:
            yahoo_symbol = f"{symbol}.KS"

        # ê¸°ê°„ë³„ ì¼ìˆ˜ ë§¤í•‘
        period_days = {
            '1m': 30,
            '3m': 90,
            '6m': 180,
            '1y': 365
        }

        days = period_days.get(period, 90)

        # ê³¼ê±° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days + 10)  # ì—¬ìœ  ìˆê²Œ

        ticker = yf.Ticker(yahoo_symbol)
        hist = ticker.history(start=start_date, end=end_date)

        if hist.empty:
            return {
                "success": False,
                "message": f"{symbol} ê³¼ê±° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        # ë°ì´í„° í¬ë§·íŒ…
        dates = []
        prices = []

        for date, row in hist.iterrows():
            dates.append(date.strftime('%Y-%m-%d'))
            prices.append(round(row['Close'], 2))

        result = {
            "success": True,
            "symbol": symbol,
            "period": period,
            "count": len(dates),
            "dates": dates,
            "prices": prices,
            "current_price": prices[-1] if prices else 0,
            "start_price": prices[0] if prices else 0,
            "change_percent": round(((prices[-1] - prices[0]) / prices[0] * 100), 2) if prices else 0
        }

        # ìºì‹œ ì €ì¥ (1ì‹œê°„)
        cache_manager.set_cached("historical-prices", result, params={"symbol": symbol, "period": period}, ttl_seconds=3600)
        logger.info(f"ğŸ’¾ {symbol} ({period}) ê°€ê²© ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")

        return result

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ê°€ê²© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        }


@app.get("/api/trending-stocks")
async def get_trending_stocks_api(min_score: int = 50, top_n: int = 15):
    """íŠ¸ë Œë”© ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ

    Args:
        min_score: ìµœì†Œ íŠ¸ë Œë”© ì ìˆ˜ (ê¸°ë³¸ê°’: 50)
        top_n: ìƒìœ„ Nê°œ ì¢…ëª© (ê¸°ë³¸ê°’: 15)

    Returns:
        íŠ¸ë Œë”© ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (í…Œë§ˆë³„ ë¶„ë¥˜)
    """
    if not TRENDING_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="íŠ¸ë Œë”© ì¢…ëª© ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        trending_stocks = get_trending_stocks(min_score=min_score, top_n=top_n)

        # í…Œë§ˆë³„ ë¶„ë¥˜
        themes = {}
        for stock in trending_stocks:
            theme = stock['theme']
            if theme not in themes:
                themes[theme] = []
            themes[theme].append(stock)

        return {
            "success": True,
            "count": len(trending_stocks),
            "stocks": trending_stocks,
            "themes": {theme: len(stocks) for theme, stocks in themes.items()},
            "generated_at": datetime.now().isoformat(),
            "message": "ë‰´ìŠ¤ ë° ì‹œì¥ ë™í–¥ ê¸°ë°˜ ê³ ìœ„í—˜ ê³ ìˆ˜ìµ íŠ¸ë Œë”© ì¢…ëª©ì…ë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŠ¸ë Œë”© ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/trending-analysis")
async def get_trending_analysis_api(request: Dict[str, Any]):
    """íŠ¸ë Œë”© ì¢…ëª© ìƒì„¸ ë¶„ì„

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: "IONQ", "RGTI")

    Returns:
        ì¢…ëª©ë³„ ìƒì„¸ ë¶„ì„ (ê°€ê²© ë³€í™”, íŠ¸ë Œë”© ì´ìœ , ê´€ë ¨ ë‰´ìŠ¤, ë¦¬ìŠ¤í¬ ìš”ì†Œ)
    """
    if not TRENDING_FEATURES_AVAILABLE:
        raise HTTPException(status_code=503, detail="íŠ¸ë Œë”© ì¢…ëª© ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    symbol = request.get("symbol", "")

    if not symbol:
        raise HTTPException(status_code=400, detail="symbol íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")

    try:
        analysis = get_trending_analysis(symbol)

        if not analysis.get('success'):
            raise HTTPException(status_code=404, detail=f"{symbol} ë¶„ì„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return analysis
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŠ¸ë Œë”© ì¢…ëª© ë¶„ì„ ì‹¤íŒ¨: {str(e)}")


# ==================== ì‚¬ìš©ìë³„ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ API ====================

class PortfolioCreateRequest(BaseModel):
    name: str
    description: Optional[str] = None
    initial_capital: float

class PortfolioPositionRequest(BaseModel):
    portfolio_id: str
    symbol: str
    shares: float
    avg_price: float

@app.get("/api/user/portfolios")
async def get_user_portfolios(current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ëª©ë¡ ì¡°íšŒ"""
    try:
        user_id = current_user["user_id"]

        # Supabaseì—ì„œ ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ
        result = supabase.table("user_portfolios").select("*").eq("user_id", user_id).execute()

        return {
            "success": True,
            "portfolios": result.data,
            "count": len(result.data)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "portfolios": []
        }

@app.post("/api/user/portfolio")
async def create_user_portfolio(request: PortfolioCreateRequest, current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±"""
    try:
        user_id = current_user["user_id"]

        # Supabaseì— í¬íŠ¸í´ë¦¬ì˜¤ ì‚½ì…
        result = supabase.table("user_portfolios").insert({
            "user_id": user_id,
            "name": request.name,
            "description": request.description,
            "initial_capital": request.initial_capital
        }).execute()

        return {
            "success": True,
            "portfolio": result.data[0] if result.data else None
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/user/portfolio/{portfolio_id}")
async def get_user_portfolio(portfolio_id: str, current_user: Dict[str, Any] = Depends(verify_token)):
    """íŠ¹ì • í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„¸ ì¡°íšŒ"""
    try:
        user_id = current_user["user_id"]

        # í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ë³¸ ì •ë³´
        portfolio_result = supabase.table("user_portfolios").select("*").eq("id", portfolio_id).eq("user_id", user_id).single().execute()

        # í¬íŠ¸í´ë¦¬ì˜¤ í¬ì§€ì…˜
        positions_result = supabase.table("portfolio_positions").select("*").eq("portfolio_id", portfolio_id).execute()

        return {
            "success": True,
            "portfolio": portfolio_result.data,
            "positions": positions_result.data
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/user/portfolio/{portfolio_id}/position")
async def add_portfolio_position(portfolio_id: str, request: PortfolioPositionRequest, current_user: Dict[str, Any] = Depends(verify_token)):
    """í¬íŠ¸í´ë¦¬ì˜¤ì— í¬ì§€ì…˜ ì¶”ê°€"""
    try:
        user_id = current_user["user_id"]

        # í¬íŠ¸í´ë¦¬ì˜¤ ì†Œìœ ê¶Œ í™•ì¸
        portfolio_result = supabase.table("user_portfolios").select("id").eq("id", portfolio_id).eq("user_id", user_id).single().execute()

        if not portfolio_result.data:
            raise HTTPException(status_code=403, detail="ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")

        # í¬ì§€ì…˜ ì¶”ê°€
        result = supabase.table("portfolio_positions").insert({
            "portfolio_id": portfolio_id,
            "symbol": request.symbol,
            "shares": request.shares,
            "avg_price": request.avg_price
        }).execute()

        return {
            "success": True,
            "position": result.data[0] if result.data else None
        }
    except HTTPException:
        raise
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/user/selections")
async def save_user_selection(request: Dict[str, Any], current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì ì¢…ëª© ì„ íƒ ê¸°ë¡ ì €ì¥"""
    try:
        user_id = current_user["user_id"]

        result = supabase.table("user_selections").insert({
            "user_id": user_id,
            "symbol": request.get("symbol"),
            "context": request.get("context"),
            "action": request.get("action", "view")
        }).execute()

        return {
            "success": True,
            "selection": result.data[0] if result.data else None
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/user/selections")
async def get_user_selections(current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì ì¢…ëª© ì„ íƒ ì´ë ¥ ì¡°íšŒ"""
    try:
        user_id = current_user["user_id"]

        result = supabase.table("user_selections").select("*").eq("user_id", user_id).order("selected_at", desc=True).limit(50).execute()

        return {
            "success": True,
            "selections": result.data,
            "count": len(result.data)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "selections": []
        }

@app.post("/api/user/ai-analysis")
async def save_user_ai_analysis(request: Dict[str, Any], current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ìë³„ AI ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    try:
        user_id = current_user["user_id"]

        result = supabase.table("user_ai_analyses").insert({
            "user_id": user_id,
            "symbol": request.get("symbol"),
            "analysis_text": request.get("analysis_text"),
            "recommendation": request.get("recommendation"),
            "confidence_score": request.get("confidence_score")
        }).execute()

        return {
            "success": True,
            "analysis": result.data[0] if result.data else None
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/user/ai-analyses")
async def get_user_ai_analyses(symbol: Optional[str] = None, current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì AI ë¶„ì„ ì´ë ¥ ì¡°íšŒ"""
    try:
        user_id = current_user["user_id"]

        query = supabase.table("user_ai_analyses").select("*").eq("user_id", user_id)

        if symbol:
            query = query.eq("symbol", symbol)

        result = query.order("created_at", desc=True).limit(50).execute()

        return {
            "success": True,
            "analyses": result.data,
            "count": len(result.data)
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "analyses": []
        }


# ==================== ì¦ê²¨ì°¾ê¸° API ====================

@app.post("/api/rag-search")
async def rag_search(request: Dict[str, Any]):
    """RAG ê¸°ë°˜ íˆ¬ì ì¸ì‚¬ì´íŠ¸ ê²€ìƒ‰ (1ì‹œê°„ ìºì‹±)

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "ì‚¼ì„±ì „ì", "HBM", "AI ë°˜ë„ì²´")
        top_k: ìƒìœ„ Kê°œ ê²°ê³¼ (ê¸°ë³¸ê°’: 5)

    Returns:
        ê´€ë ¨ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    try:
        query = request.get("query", "")
        top_k = request.get("top_k", 5)

        if not query or not query.strip():
            return {
                "success": False,
                "message": "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            }

        # ìºì‹œ ì¡°íšŒ (query + top_kë¡œ 1ì‹œê°„ ìºì‹±)
        cache_params = {"query": query, "top_k": top_k}
        cached = cache_manager.get_cached("rag-search", params=cache_params, ttl_seconds=3600)
        if cached:
            logger.info(f"âœ… ìºì‹œì—ì„œ RAG ê²€ìƒ‰ ë°˜í™˜ (query={query}, top_k={top_k})")
            return cached

        logger.info(f"ğŸ”„ RAG ê²€ìƒ‰ ìƒˆë¡œ ê³„ì‚° ì¤‘ (query={query}, top_k={top_k})")

        # Supabase RAG ê²€ìƒ‰
        insights = get_relevant_insights(query, top_k=top_k)

        if not insights:
            result = {
                "success": True,
                "query": query,
                "insights": [],
                "count": 0,
                "message": f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

            # ìºì‹œ ì €ì¥ (1ì‹œê°„)
            cache_manager.set_cached("rag-search", result, params=cache_params, ttl_seconds=3600)
            logger.info(f"ğŸ’¾ RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ ìºì‹œ ì €ì¥ ì™„ë£Œ (query={query})")

            return result

        result = {
            "success": True,
            "query": query,
            "insights": insights,
            "count": len(insights),
            "message": f"'{query}'ì— ëŒ€í•œ {len(insights)}ê°œì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        }

        # ìºì‹œ ì €ì¥ (1ì‹œê°„)
        cache_manager.set_cached("rag-search", result, params=cache_params, ttl_seconds=3600)
        logger.info(f"ğŸ’¾ RAG ê²€ìƒ‰ ìºì‹œ ì €ì¥ ì™„ë£Œ (query={query}, {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸)")

        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
        }


@app.post("/api/user/favorites")
async def add_favorite(request: Dict[str, Any], current_user: Dict[str, Any] = Depends(verify_token)):
    """ì¦ê²¨ì°¾ê¸°ì— ì¢…ëª© ì¶”ê°€

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼

    Returns:
        ì¶”ê°€ëœ ì¦ê²¨ì°¾ê¸° ì •ë³´
    """
    try:
        user_id = current_user["user_id"]
        symbol = request.get("symbol")

        if not symbol:
            raise HTTPException(status_code=400, detail="symbolì´ í•„ìš”í•©ë‹ˆë‹¤")

        # ì´ë¯¸ ì¦ê²¨ì°¾ê¸°ì— ìˆëŠ”ì§€ í™•ì¸ (admin í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        if not supabase_admin:
            raise HTTPException(status_code=500, detail="ê´€ë¦¬ì ê¶Œí•œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        existing = supabase_admin.table("user_favorites").select("*").eq("user_id", user_id).eq("symbol", symbol).execute()

        if existing.data:
            # ì´ë¯¸ ìˆì–´ë„ ìºì‹œ ë¬´íš¨í™” (UI ë™ê¸°í™”ë¥¼ ìœ„í•´)
            cache_manager.invalidate_cache("favorites", {"user_id": user_id})
            logger.info(f"ğŸ—‘ï¸ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ìºì‹œ ë¬´íš¨í™” (ì´ë¯¸ ì¡´ì¬: {symbol})")
            return {
                "success": True,
                "message": "ì´ë¯¸ ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤",
                "favorite": existing.data[0]
            }

        # ì¦ê²¨ì°¾ê¸° ì¶”ê°€ (admin í´ë¼ì´ì–¸íŠ¸ë¡œ RLS ìš°íšŒ)
        result = supabase_admin.table("user_favorites").insert({
            "user_id": user_id,
            "symbol": symbol
        }).execute()

        # ìºì‹œ ë¬´íš¨í™” (ì¦ê²¨ì°¾ê¸° ëª©ë¡ì´ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ)
        cache_manager.invalidate_cache("favorites", {"user_id": user_id})
        logger.info(f"ğŸ—‘ï¸ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ìºì‹œ ë¬´íš¨í™” (ì¶”ê°€: {symbol})")

        return {
            "success": True,
            "message": "ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤",
            "favorite": result.data[0] if result.data else None
        }
    except HTTPException:
        raise
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ì¦ê²¨ì°¾ê¸° ì¶”ê°€ ì‹¤íŒ¨: {str(e)}"
        }


@app.delete("/api/user/favorites/{symbol}")
async def remove_favorite(symbol: str, current_user: Dict[str, Any] = Depends(verify_token)):
    """ì¦ê²¨ì°¾ê¸°ì—ì„œ ì¢…ëª© ì œê±°

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼

    Returns:
        ì‚­ì œ ê²°ê³¼
    """
    try:
        user_id = current_user["user_id"]

        # ì¦ê²¨ì°¾ê¸° ì‚­ì œ (admin í´ë¼ì´ì–¸íŠ¸ë¡œ RLS ìš°íšŒ)
        if not supabase_admin:
            raise HTTPException(status_code=500, detail="ê´€ë¦¬ì ê¶Œí•œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        result = supabase_admin.table("user_favorites").delete().eq("user_id", user_id).eq("symbol", symbol).execute()

        # ìºì‹œ ë¬´íš¨í™” (ì¦ê²¨ì°¾ê¸° ëª©ë¡ì´ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ)
        cache_manager.invalidate_cache("favorites", {"user_id": user_id})
        logger.info(f"ğŸ—‘ï¸ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ìºì‹œ ë¬´íš¨í™” (ì‚­ì œ: {symbol})")

        return {
            "success": True,
            "message": "ì¦ê²¨ì°¾ê¸°ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ì¦ê²¨ì°¾ê¸° ì œê±° ì‹¤íŒ¨: {str(e)}"
        }


@app.get("/api/blog-update-info")
async def get_blog_update_info():
    """ë¸”ë¡œê·¸ ìµœì‹  ì—…ë°ì´íŠ¸ ì‹œê°„ ì¡°íšŒ

    Returns:
        ìµœê·¼ ë¸”ë¡œê·¸ ê¸€ ë‚ ì§œ ë° ì „ì²´ ë°ì´í„° ìˆ˜
    """
    try:
        # Supabaseì—ì„œ ìµœì‹  ë¸”ë¡œê·¸ ë‚ ì§œ ì¡°íšŒ
        response = supabase_rag.client.table('investment_insights') \
            .select('date') \
            .order('date', desc=True) \
            .limit(1) \
            .execute()

        # ì „ì²´ ë°ì´í„° ìˆ˜ ì¡°íšŒ
        count_response = supabase_rag.client.table('investment_insights') \
            .select('id', count='exact') \
            .execute()

        if response.data and len(response.data) > 0:
            latest_date = response.data[0]['date']
            total_count = count_response.count if hasattr(count_response, 'count') else len(count_response.data)

            # ë‚ ì§œë¥¼ í•œêµ­ì–´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (YYYY-MM-DD HH:MM)
            from datetime import datetime
            try:
                date_obj = datetime.strptime(latest_date, '%Y-%m-%d')
                formatted_date = date_obj.strftime('%Yë…„ %mì›” %dì¼')
            except:
                formatted_date = latest_date

            return {
                "success": True,
                "latest_date": latest_date,
                "formatted_date": formatted_date,
                "total_insights": total_count,
                "message": f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {formatted_date}"
            }
        else:
            return {
                "success": False,
                "message": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
            }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": f"ì—…ë°ì´íŠ¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        }


@app.get("/api/user/favorites")
async def get_favorites(current_user: Dict[str, Any] = Depends(verify_token)):
    """ì‚¬ìš©ì ì¦ê²¨ì°¾ê¸° ëª©ë¡ ì¡°íšŒ (30ë¶„ ìºì‹±)

    Returns:
        ì¦ê²¨ì°¾ê¸° ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (ì¢…ëª© ì •ë³´ í¬í•¨)
    """
    try:
        user_id = current_user["user_id"]

        # ìºì‹œ ì¡°íšŒ (ì‚¬ìš©ìë³„ 30ë¶„ ìºì‹±)
        cached = cache_manager.get_cached("favorites", params={"user_id": user_id}, ttl_seconds=1800)
        if cached:
            logger.info(f"âœ… ìºì‹œì—ì„œ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ë°˜í™˜")
            return cached

        logger.info(f"ğŸ”„ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ìƒˆë¡œ ì¡°íšŒ ì¤‘...")

        # ì¦ê²¨ì°¾ê¸° ëª©ë¡ ì¡°íšŒ (admin í´ë¼ì´ì–¸íŠ¸ë¡œ RLS ìš°íšŒ)
        if not supabase_admin:
            raise HTTPException(status_code=500, detail="ê´€ë¦¬ì ê¶Œí•œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        result = supabase_admin.table("user_favorites").select("*").eq("user_id", user_id).order("created_at", desc=True).execute()

        logger.info(f"ğŸ“Š ì¡°íšŒ ê²°ê³¼: {len(result.data)}ê°œ ì¢…ëª© ë°œê²¬")

        # ê° ì¢…ëª©ì˜ ì‹¤ì‹œê°„ ì •ë³´ ì¶”ê°€
        favorites_with_info = []

        for favorite in result.data:
            symbol = favorite['symbol']

            try:
                import yfinance as yf
                from src.tools.yahoo_finance import yahoo_analyzer

                # í•œêµ­ ì¢…ëª© ì½”ë“œ ë³€í™˜
                yahoo_symbol = symbol
                if symbol.isdigit() and len(symbol) == 6:
                    yahoo_symbol = f"{symbol}.KS"

                # ì¢…ëª© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                metrics = yahoo_analyzer.calculate_financial_metrics(yahoo_symbol)
                ticker = yf.Ticker(yahoo_symbol)
                info = ticker.info

                if metrics:
                    favorites_with_info.append({
                        "symbol": symbol,
                        "company_name": info.get('longName', symbol),
                        "current_price": metrics.get('current_price', 0),
                        "change_percent": metrics.get('change_percent', 0),
                        "volume": metrics.get('volume', 0),
                        "market_cap": metrics.get('market_cap', 0),
                        "score": metrics.get('score', 0),
                        "returns_1y": metrics.get('returns_1y', 0),
                        "volatility": metrics.get('volatility', 0),
                        "pe_ratio": metrics.get('pe_ratio', 'N/A'),
                        "created_at": favorite.get('created_at', '')
                    })
            except Exception as e:
                print(f"ì¢…ëª© {symbol} ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ìœ ì§€
                favorites_with_info.append({
                    "symbol": symbol,
                    "company_name": symbol,
                    "current_price": 0,
                    "created_at": favorite.get('created_at', ''),
                    "error": str(e)
                })

        response = {
            "success": True,
            "favorites": favorites_with_info,
            "count": len(favorites_with_info)
        }

        # ìºì‹œ ì €ì¥ (30ë¶„)
        cache_manager.set_cached("favorites", response, params={"user_id": user_id}, ttl_seconds=1800)
        logger.info(f"ğŸ’¾ ì‚¬ìš©ì {user_id[:8]}ì˜ ì¦ê²¨ì°¾ê¸° ìºì‹œ ì €ì¥ ì™„ë£Œ")

        return response
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "favorites": [],
            "message": f"ì¦ê²¨ì°¾ê¸° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        }


@app.get("/api/recommendation-reason")
async def get_recommendation_reason(symbol: str):
    """AIê°€ ì¢…ëª©ì„ ì¶”ì²œí•œ ì´ìœ  ìƒì„¸ ë¶„ì„

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼

    Returns:
        ì¶”ì²œ ì´ìœ , ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸, ê°€ê²© ë³€ë™ ë¶„ì„
    """
    try:
        import yfinance as yf
        from datetime import datetime, timedelta

        logger.info(f"ğŸ” {symbol} AI ì¶”ì²œ ì´ìœ  ë¶„ì„ ì‹œì‘...")

        # 1. ì¢…ëª© ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        yahoo_symbol = symbol
        if symbol.isdigit() and len(symbol) == 6:
            yahoo_symbol = f"{symbol}.KS"

        ticker = yf.Ticker(yahoo_symbol)
        info = ticker.info
        company_name = info.get('longName', symbol)
        sector = info.get('sector', 'ì •ë³´ ì—†ìŒ')

        # 2. ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ (ìƒìœ„ 5ê°œ)
        insights = get_relevant_insights(symbol, top_k=5)

        # 3. ê° ì¸ì‚¬ì´íŠ¸ì˜ ë‚ ì§œì™€ ê·¸ ì´í›„ ê°€ê²© ë³€ë™ ë¶„ì„
        insight_analysis = []

        for insight in insights:
            try:
                # ì¸ì‚¬ì´íŠ¸ ë‚ ì§œ íŒŒì‹± (ì—¬ëŸ¬ í˜•ì‹ ì§€ì›)
                insight_date_str = insight.get('date', '')

                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
                date_formats = [
                    '%Y-%m-%d',  # 2023-06-08
                    '%Y. %m. %d. %H:%M',  # 2023. 6. 8. 0:10
                    '%Y-%m-%d %H:%M:%S'  # 2023-06-08 00:10:00
                ]

                insight_date = None
                for fmt in date_formats:
                    try:
                        insight_date = datetime.strptime(insight_date_str, fmt)
                        break
                    except ValueError:
                        continue

                if insight_date is None:
                    logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ (í˜•ì‹ ë¶ˆì¼ì¹˜): {insight_date_str}")
                    continue

                # ê·¸ ë‚ ì§œì˜ ê°€ê²©ê³¼ í˜„ì¬ ê°€ê²© ë¹„êµ
                start_date = insight_date
                end_date = datetime.now()

                hist = ticker.history(start=start_date, end=end_date)

                if not hist.empty:
                    past_price = hist['Close'].iloc[0]
                    current_price = hist['Close'].iloc[-1]
                    price_change = ((current_price - past_price) / past_price) * 100

                    insight_analysis.append({
                        "title": insight.get('title', ''),
                        "date": insight_date_str,
                        "content_preview": insight.get('content', '')[:200] + "...",
                        "past_price": round(past_price, 2),
                        "current_price": round(current_price, 2),
                        "price_change_pct": round(price_change, 2),
                        "similarity": insight.get('similarity', 0),
                        "keywords": insight.get('keywords', [])[:5],
                        "sector": insight.get('sector', ''),
                        "url": insight.get('url', '')
                    })
            except Exception as e:
                logger.warning(f"ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                continue

        # 4. ì„¹í„° ê´€ë ¨ ì¢…ëª©ë“¤ ê°€ê²© ë³€ë™ (ê°„ë‹¨í•˜ê²Œ S&P 500 ìƒìœ„ ì¢…ëª© ì¤‘ ê°™ì€ ì„¹í„°ë§Œ)
        sector_stocks = []

        if sector != 'ì •ë³´ ì—†ìŒ':
            # AI ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°™ì€ ì„¹í„° ì°¾ê¸°
            try:
                from src.tools.yahoo_finance import get_top_stocks
                top_stocks = get_top_stocks(20)

                for stock in top_stocks[:10]:  # ìƒìœ„ 10ê°œë§Œ
                    if stock['ticker'] == symbol:
                        continue

                    try:
                        stock_ticker = yf.Ticker(stock['ticker'])
                        stock_info = stock_ticker.info
                        stock_sector = stock_info.get('sector', '')

                        if stock_sector == sector:
                            # ìµœê·¼ 3ê°œì›” ìˆ˜ìµë¥ 
                            hist_3m = stock_ticker.history(period="3mo")
                            if not hist_3m.empty:
                                start_price = hist_3m['Close'].iloc[0]
                                end_price = hist_3m['Close'].iloc[-1]
                                returns_3m = ((end_price - start_price) / start_price) * 100

                                sector_stocks.append({
                                    "symbol": stock['ticker'],
                                    "company_name": stock_info.get('longName', stock['ticker']),
                                    "returns_3m": round(returns_3m, 2)
                                })
                    except Exception as e:
                        logger.warning(f"{stock['ticker']} ì„¹í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
                        continue
            except Exception as e:
                logger.warning(f"ì„¹í„° ì¢…ëª© ë¶„ì„ ì‹¤íŒ¨: {e}")

        # 5. ì¶”ì²œ ì´ìœ  ìš”ì•½ ìƒì„±
        recommendation_summary = f"""
**{company_name} ({symbol})**ì„ AIê°€ ì¶”ì²œí•œ ì´ìœ ì…ë‹ˆë‹¤.

### ğŸ“Š ì„¹í„° ë° ê¸°ë³¸ ì •ë³´
- **ì„¹í„°**: {sector}
- **ë¶„ì„ëœ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸**: {len(insight_analysis)}ê°œ

### ğŸ’¡ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ë¶„ì„
"""

        if insight_analysis:
            avg_price_change = sum(i['price_change_pct'] for i in insight_analysis) / len(insight_analysis)
            recommendation_summary += f"\në¸”ë¡œê·¸ ê¸€ ì‘ì„± ì´í›„ í‰ê·  ê°€ê²© ë³€ë™: **{avg_price_change:+.2f}%**\n\n"

            if avg_price_change > 10:
                recommendation_summary += "âœ… ë¸”ë¡œê·¸ì—ì„œ ì–¸ê¸‰ëœ ì´í›„ **ê°•í•œ ìƒìŠ¹ì„¸**ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
            elif avg_price_change > 0:
                recommendation_summary += "ğŸ“ˆ ë¸”ë¡œê·¸ì—ì„œ ì–¸ê¸‰ëœ ì´í›„ **ê¸ì •ì ì¸ ì„±ê³¼**ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
            else:
                recommendation_summary += "ğŸ“‰ ë¸”ë¡œê·¸ ì–¸ê¸‰ ì´í›„ **ê°€ê²© ì¡°ì •** ë‹¨ê³„ì— ìˆìœ¼ë‚˜, ì¥ê¸° ì „ë§ì€ ê¸ì •ì ì…ë‹ˆë‹¤.\n\n"
        else:
            recommendation_summary += "\nâš ï¸ ê´€ë ¨ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ìˆ ì  ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"

        # 6. ì„¹í„° ë™í–¥ ë¶„ì„
        if sector_stocks:
            avg_sector_returns = sum(s['returns_3m'] for s in sector_stocks) / len(sector_stocks)
            recommendation_summary += f"""
### ğŸ­ {sector} ì„¹í„° ë™í–¥
- **ì„¹í„° í‰ê·  3ê°œì›” ìˆ˜ìµë¥ **: {avg_sector_returns:+.2f}%
- **ë¶„ì„ëœ ë™ì¢… ì—…ê³„ ì¢…ëª©**: {len(sector_stocks)}ê°œ

"""
            if avg_sector_returns > 5:
                recommendation_summary += "ğŸ”¥ ì„¹í„° ì „ì²´ê°€ ê°•í•œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆì–´ **ê¸ì •ì ì¸ ì‹œì¥ í™˜ê²½**ì…ë‹ˆë‹¤.\n\n"
            elif avg_sector_returns > 0:
                recommendation_summary += "ğŸ“Š ì„¹í„°ê°€ **ì•ˆì •ì ì¸ ì„±ì¥**ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
            else:
                recommendation_summary += "âš ï¸ ì„¹í„°ê°€ ì¼ì‹œì ì¸ ì¡°ì • ì¤‘ì´ë‚˜, **ì„ ë³„ì  íˆ¬ì ê¸°íšŒ**ê°€ ìˆìŠµë‹ˆë‹¤.\n\n"

        recommendation_summary += """
### ğŸ¯ ì¢…í•© ì¶”ì²œ ì´ìœ 
AIëŠ” ë‹¤ìŒ ìš”ì†Œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì´ ì¢…ëª©ì„ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤:
1. ìµœê·¼ ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ì—ì„œ ê¸ì •ì ì¸ ì–¸ê¸‰
2. ê³¼ê±° ì–¸ê¸‰ ì´í›„ì˜ ì‹¤ì œ ê°€ê²© ì„±ê³¼
3. ì„¹í„° ì „ë°˜ì˜ ë™í–¥ ë° ì‹œì¥ í™˜ê²½
4. ê¸°ìˆ ì  ì§€í‘œ ë° ìˆ˜ìµë¥  ë¶„ì„

**ì´ ì¢…ëª©ì€ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„ ë³„ëœ íˆ¬ì ê¸°íšŒì…ë‹ˆë‹¤.**
"""

        return {
            "success": True,
            "symbol": symbol,
            "company_name": company_name,
            "sector": sector,
            "insights_count": len(insight_analysis),
            "insights": insight_analysis,
            "sector_stocks": sector_stocks,
            "recommendation_summary": recommendation_summary.strip()
        }

    except Exception as e:
        logger.error(f"âŒ AI ì¶”ì²œ ì´ìœ  ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": f"AI ì¶”ì²œ ì´ìœ  ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        }


@app.post("/api/asset-allocation")
async def get_asset_allocation(request: Dict[str, Any] = None):
    """
    ì´ì²´ì  ìì‚° ë°°ë¶„ ì œì•ˆ API (ë§¤í¬ë¡œ ê²½ì œ, í™˜ìœ¨, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì¢…í•© ë¶„ì„)

    Args:
        request: {
            "investment_amount": íˆ¬ì ê¸ˆì•¡ (ê¸°ë³¸ 1ì–µì›),
            "risk_tolerance": ë¦¬ìŠ¤í¬ í—ˆìš©ë„ (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ, ê¸°ë³¸ ë³´í†µ)
        }

    Returns:
        ìì‚° ë°°ë¶„ ì¶”ì²œ, ì‹œì¥ í™˜ê²½ ë¶„ì„, ë¦¬ìŠ¤í¬ í‰ê°€
    """
    if request is None:
        request = {}

    # ìºì‹œ ì¡°íšŒ (investment_amount + risk_toleranceë¡œ 1ì‹œê°„ ìºì‹±)
    investment_amount = request.get("investment_amount", 100000000)
    risk_tolerance = request.get("risk_tolerance", "ë³´í†µ")
    cache_params = {"investment_amount": investment_amount, "risk_tolerance": risk_tolerance}
    cached = cache_manager.get_cached("asset-allocation", params=cache_params, ttl_seconds=3600)
    if cached:
        logger.info(f"âœ… ìºì‹œì—ì„œ ìì‚° ë°°ë¶„ ì œì•ˆ ë°˜í™˜ (íˆ¬ìê¸ˆì•¡: {investment_amount:,}ì›, ë¦¬ìŠ¤í¬: {risk_tolerance})")
        return cached

    try:
        from src.agents.asset_allocation_agent import get_asset_allocation_agent
        from src.tools.forex_data import analyze_forex_market
        from src.tools.news_aggregator import analyze_geopolitical_risks

        logger.info(f"ğŸ”„ ìì‚° ë°°ë¶„ ì œì•ˆ ìƒˆë¡œ ê³„ì‚° ì¤‘ (íˆ¬ìê¸ˆì•¡: {investment_amount:,}ì›, ë¦¬ìŠ¤í¬: {risk_tolerance})")

        # ìì‚° ë°°ë¶„ ì—ì´ì „íŠ¸ ì‹¤í–‰
        agent = get_asset_allocation_agent()
        recommendation = agent.generate_asset_allocation(
            investment_amount=investment_amount,
            risk_tolerance=risk_tolerance
        )

        if not recommendation:
            return {
                "success": False,
                "message": "ìì‚° ë°°ë¶„ ì œì•ˆì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        # í™˜ìœ¨ ì‹œì¥ ë¶„ì„ ì¶”ê°€
        forex_analysis = analyze_forex_market()

        # ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ ì¶”ê°€
        geo_risk = analyze_geopolitical_risks(days=7)

        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary = agent.get_allocation_summary(recommendation)

        result = {
            "success": True,
            "investment_amount": investment_amount,
            "risk_tolerance": risk_tolerance,
            "recommendation": {
                "allocations": [
                    {
                        "asset_class": alloc.asset_class,
                        "allocation_percent": alloc.allocation_percent,
                        "reasoning": alloc.reasoning,
                        "instruments": alloc.instruments,
                        "risk_level": alloc.risk_level
                    }
                    for alloc in recommendation.allocations
                ],
                "total_allocation": recommendation.total_allocation,
                "market_environment": recommendation.market_environment,
                "risk_assessment": recommendation.risk_assessment,
                "rebalancing_frequency": recommendation.rebalancing_frequency,
                "key_catalysts": recommendation.key_catalysts,
                "warnings": recommendation.warnings
            },
            "summary": summary,
            "forex_analysis": {
                "krw_usd_trend": forex_analysis.get("krw_usd_trend", {}),
                "dollar_index": forex_analysis.get("dollar_index", {})
            },
            "geopolitical_risk": geo_risk,
            "generated_at": datetime.now().isoformat(),
            "message": "ë§¤í¬ë¡œ ê²½ì œ, í™˜ìœ¨, ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ë¥¼ ì¢…í•©í•œ ìì‚° ë°°ë¶„ ì œì•ˆì…ë‹ˆë‹¤."
        }

        # ìºì‹œ ì €ì¥ (1ì‹œê°„)
        cache_manager.set_cached("asset-allocation", result, params=cache_params, ttl_seconds=3600)
        logger.info(f"ğŸ’¾ ìì‚° ë°°ë¶„ ì œì•ˆ ìºì‹œ ì €ì¥ ì™„ë£Œ (íˆ¬ìê¸ˆì•¡: {investment_amount:,}ì›, ë¦¬ìŠ¤í¬: {risk_tolerance})")

        return result

    except Exception as e:
        logger.error(f"âŒ ìì‚° ë°°ë¶„ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "message": f"ìì‚° ë°°ë¶„ ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8888)