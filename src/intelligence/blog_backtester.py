"""ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ë°±í…ŒìŠ¤íŒ… ì—”ì§„

ë§¤ì¼ ë¸”ë¡œê·¸ ê¸€ì„ ì‹œì ë³„ë¡œ ë¶„ì„í•˜ì—¬ ì‹¤ì œ ì‹œì¥ ë³€í™”ì™€ ë¹„êµ
ì¸ì‚¬ì´íŠ¸-ê²°ê³¼ ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•˜ê³  ì‹ ë¢°ë„ë¥¼ í‰ê°€
"""
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from pathlib import Path
import pandas as pd
import numpy as np
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class BlogInsight:
    """ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""
    blog_id: int
    title: str
    content: str
    date: datetime
    url: str
    keywords: List[str]
    sentiment: float  # -1.0 (ë¶€ì •) ~ 1.0 (ê¸ì •)


@dataclass
class MarketOutcome:
    """ì‹œì¥ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    ticker: str
    start_date: datetime
    end_date: datetime
    start_price: float
    end_price: float
    return_pct: float
    volatility: float


@dataclass
class BacktestResult:
    """ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    insight: BlogInsight
    prediction_topic: str
    prediction_direction: str  # "ìƒìŠ¹", "í•˜ë½", "ì¤‘ë¦½"
    actual_outcome: MarketOutcome
    correlation_score: float  # -1.0 ~ 1.0
    confidence_level: str  # "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
    success: bool


class BlogBacktester:
    """ë¸”ë¡œê·¸ ë°±í…ŒìŠ¤íŒ… ì—”ì§„"""

    def __init__(self, blog_data_path: str = "data/blog_raw_all.json"):
        self.blog_data_path = Path(blog_data_path)
        self.blogs = self._load_blogs()
        logger.info(f"âœ… {len(self.blogs)}ê°œ ë¸”ë¡œê·¸ ê¸€ ë¡œë“œ ì™„ë£Œ")

    def _load_blogs(self) -> List[Dict]:
        """ë¸”ë¡œê·¸ ë°ì´í„° ë¡œë“œ"""
        if not self.blog_data_path.exists():
            logger.error(f"âŒ ë¸”ë¡œê·¸ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {self.blog_data_path}")
            return []

        with open(self.blog_data_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)"""
        if not date_str:
            return None

        # "2025. 10. 2. 0:10" í˜•ì‹
        try:
            date_str = date_str.strip()
            # ". " -> "-" ë³€í™˜
            date_str = date_str.replace('. ', '-').replace('.', '').strip()
            parts = date_str.split()

            if len(parts) >= 3:
                year = int(parts[0])
                month = int(parts[1])
                day = int(parts[2])
                return datetime(year, month, day)
        except Exception as e:
            logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}, ì—ëŸ¬: {e}")
            return None

        return None

    def segment_blogs_by_time(self, months_back: int = 12) -> Dict[str, List[BlogInsight]]:
        """ì‹œì ë³„ë¡œ ë¸”ë¡œê·¸ ë¶„í• 

        Args:
            months_back: ëª‡ ê°œì›” ì „ê¹Œì§€ ë°ì´í„°ë¥¼ ë¶„í• í• ì§€

        Returns:
            {"2024-01": [BlogInsight, ...], "2024-02": [...], ...}
        """
        segments = {}
        now = datetime.now()

        for blog in self.blogs:
            date = self._parse_date(blog.get('date', ''))
            if not date:
                continue

            # ë„ˆë¬´ ì˜¤ë˜ëœ ë°ì´í„°ëŠ” ì œì™¸
            if (now - date).days > months_back * 30:
                continue

            # ì›”ë³„ë¡œ ê·¸ë£¹í™”
            month_key = date.strftime("%Y-%m")

            if month_key not in segments:
                segments[month_key] = []

            # BlogInsight ê°ì²´ ìƒì„±
            insight = BlogInsight(
                blog_id=blog.get('id', 0),
                title=blog.get('title', ''),
                content=blog.get('content', ''),
                date=date,
                url=blog.get('url', ''),
                keywords=self._extract_keywords(blog.get('content', '')),
                sentiment=self._calculate_sentiment(blog.get('content', ''))
            )

            segments[month_key].append(insight)

        logger.info(f"âœ… {len(segments)}ê°œ ì›”ë³„ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì™„ë£Œ")
        return segments

    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ì£¼ìš” í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        keywords = [
            # ì¢…ëª©/ê¸°ì—…
            "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤", "TSMC", "ì—”ë¹„ë””ì•„", "ì• í”Œ", "í…ŒìŠ¬ë¼",
            "ì•„ë§ˆì¡´", "êµ¬ê¸€", "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸", "ë©”íƒ€",

            # ì„¹í„°/ì‚°ì—…
            "ë°˜ë„ì²´", "AI", "ì¸ê³µì§€ëŠ¥", "ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ë°”ì´ì˜¤", "ì œì•½",
            "ì€í–‰", "ê¸ˆìœµ", "ë¶€ë™ì‚°", "ê±´ì„¤", "ìë™ì°¨", "í•­ê³µ", "ì—¬í–‰",

            # ê²½ì œ/ì •ì±…
            "ê¸ˆë¦¬", "ì¸í”Œë ˆì´ì…˜", "GDP", "ì‹¤ì—…ë¥ ", "ì–‘ì ì™„í™”", "ê¸´ì¶•",
            "ë¬´ì—­ì „ìŸ", "ê´€ì„¸", "í™˜ìœ¨", "ë‹¬ëŸ¬", "ì›í™”",

            # íˆ¬ì ì „ëµ
            "ë§¤ìˆ˜", "ë§¤ë„", "ë³´ìœ ", "ì €í‰ê°€", "ê³ í‰ê°€", "ì„±ì¥ì£¼", "ê°€ì¹˜ì£¼",
            "ë°°ë‹¹", "ë¶„í• ", "í•©ë³‘", "IPO", "ìƒì¥",

            # ì‹œì¥ ìƒí™©
            "ê°•ì„¸", "ì•½ì„¸", "ì¡°ì •", "ë°˜ë“±", "í•˜ë½", "ìƒìŠ¹", "íš¡ë³´",
            "ë³€ë™ì„±", "ìœ ë™ì„±", "ê±°ë˜ëŸ‰"
        ]

        found_keywords = []
        text_lower = text.lower()

        for keyword in keywords:
            if keyword.lower() in text_lower or keyword in text:
                found_keywords.append(keyword)

        return list(set(found_keywords))  # ì¤‘ë³µ ì œê±°

    def _calculate_sentiment(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„ (-1.0 ~ 1.0)"""
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ê°ì„± ë¶„ì„
        positive_words = [
            "ìƒìŠ¹", "í˜¸í™©", "ì„±ì¥", "ì¦ê°€", "ê°œì„ ", "íšŒë³µ", "ê°•ì„¸", "ê¸ì •",
            "ì¢‹", "í›Œë¥­", "ìµœê³ ", "ë§¤ìˆ˜", "ì¶”ì²œ", "ê¸°ëŒ€", "ì „ë§", "ë‚™ê´€"
        ]

        negative_words = [
            "í•˜ë½", "ë¶ˆí™©", "ê°ì†Œ", "ì•…í™”", "ë¶€ì§„", "ì•½ì„¸", "ë¶€ì •",
            "ë‚˜ì¨", "ìµœì•…", "ë§¤ë„", "ìš°ë ¤", "ìœ„í—˜", "ë¹„ê´€", "ì†ì‹¤"
        ]

        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        total = positive_count + negative_count
        if total == 0:
            return 0.0

        sentiment = (positive_count - negative_count) / total
        return max(-1.0, min(1.0, sentiment))

    def extract_predictions_from_insights(self, insights: List[BlogInsight]) -> List[Dict]:
        """ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸ì—ì„œ ì˜ˆì¸¡ ì¶”ì¶œ

        ì˜ˆ: "ì‚¼ì„±ì „ì ë°˜ë„ì²´ í˜¸í™©" -> {"ticker": "005930.KS", "direction": "ìƒìŠ¹"}
        """
        predictions = []

        # í‚¤ì›Œë“œ -> ì¢…ëª© ì‹¬ë³¼ ë§¤í•‘
        keyword_to_ticker = {
            "ì‚¼ì„±ì „ì": "005930.KS",
            "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS",
            "TSMC": "TSM",
            "ì—”ë¹„ë””ì•„": "NVDA",
            "ì• í”Œ": "AAPL",
            "í…ŒìŠ¬ë¼": "TSLA",
            "ì•„ë§ˆì¡´": "AMZN",
            "êµ¬ê¸€": "GOOGL",
            "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸": "MSFT",
            "ë©”íƒ€": "META",
            # ì„¹í„° ETFë¡œ ë³€í™˜
            "ë°˜ë„ì²´": "SMH",  # VanEck Semiconductor ETF
            "AI": "BOTZ",  # AI & Robotics ETF
            "ì „ê¸°ì°¨": "LIT",  # Lithium & Battery ETF
            "ë°”ì´ì˜¤": "XBI",  # Biotech ETF
        }

        for insight in insights:
            for keyword in insight.keywords:
                if keyword in keyword_to_ticker:
                    ticker = keyword_to_ticker[keyword]

                    # ê°ì„± ë¶„ì„ ê²°ê³¼ë¡œ ë°©í–¥ ì˜ˆì¸¡
                    if insight.sentiment > 0.2:
                        direction = "ìƒìŠ¹"
                    elif insight.sentiment < -0.2:
                        direction = "í•˜ë½"
                    else:
                        direction = "ì¤‘ë¦½"

                    predictions.append({
                        "insight": insight,
                        "ticker": ticker,
                        "direction": direction,
                        "confidence": abs(insight.sentiment)
                    })

        return predictions

    async def backtest_insight(
        self,
        insight: BlogInsight,
        ticker: str,
        direction: str,
        test_period_months: int = 3
    ) -> Optional[BacktestResult]:
        """ê°œë³„ ì¸ì‚¬ì´íŠ¸ ë°±í…ŒìŠ¤íŒ…

        Args:
            insight: ë¸”ë¡œê·¸ ì¸ì‚¬ì´íŠ¸
            ticker: ì¢…ëª© ì‹¬ë³¼
            direction: ì˜ˆì¸¡ ë°©í–¥ ("ìƒìŠ¹", "í•˜ë½", "ì¤‘ë¦½")
            test_period_months: í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ê°œì›”)

        Returns:
            BacktestResult ë˜ëŠ” None
        """
        try:
            import yfinance as yf

            # ì‹¤ì œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
            start_date = insight.date
            end_date = start_date + timedelta(days=test_period_months * 30)

            stock = yf.Ticker(ticker)
            hist = stock.history(start=start_date, end=end_date)

            if hist.empty or len(hist) < 5:
                logger.warning(f"âš ï¸ {ticker} ë°ì´í„° ë¶€ì¡±: {start_date} ~ {end_date}")
                return None

            # ì‹œì‘/ì¢…ë£Œ ê°€ê²©
            start_price = hist['Close'].iloc[0]
            end_price = hist['Close'].iloc[-1]
            return_pct = ((end_price - start_price) / start_price) * 100

            # ë³€ë™ì„± ê³„ì‚°
            daily_returns = hist['Close'].pct_change().dropna()
            volatility = daily_returns.std() * np.sqrt(252) * 100  # ì—°ê°„í™”

            # ì‹¤ì œ ê²°ê³¼
            outcome = MarketOutcome(
                ticker=ticker,
                start_date=start_date,
                end_date=end_date,
                start_price=float(start_price),
                end_price=float(end_price),
                return_pct=float(return_pct),
                volatility=float(volatility)
            )

            # ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ
            actual_direction = "ìƒìŠ¹" if return_pct > 2 else "í•˜ë½" if return_pct < -2 else "ì¤‘ë¦½"

            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            if direction == actual_direction:
                correlation_score = 0.8 + (abs(return_pct) / 100) * 0.2  # 0.8 ~ 1.0
            elif direction == "ì¤‘ë¦½" or actual_direction == "ì¤‘ë¦½":
                correlation_score = 0.5  # ì¤‘ë¦½
            else:
                correlation_score = -0.5 - (abs(return_pct) / 100) * 0.5  # -0.5 ~ -1.0

            correlation_score = max(-1.0, min(1.0, correlation_score))

            # ì‹ ë¢°ë„ ë ˆë²¨
            if abs(correlation_score) > 0.7:
                confidence_level = "ë†’ìŒ"
            elif abs(correlation_score) > 0.4:
                confidence_level = "ì¤‘ê°„"
            else:
                confidence_level = "ë‚®ìŒ"

            # ì„±ê³µ ì—¬ë¶€
            success = (direction == actual_direction)

            result = BacktestResult(
                insight=insight,
                prediction_topic=ticker,
                prediction_direction=direction,
                actual_outcome=outcome,
                correlation_score=correlation_score,
                confidence_level=confidence_level,
                success=success
            )

            logger.info(f"âœ… ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ: {ticker} ({direction}) -> ì‹¤ì œ {actual_direction} (ìˆ˜ìµë¥ : {return_pct:.2f}%)")
            return result

        except Exception as e:
            logger.error(f"âŒ ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨: {ticker}, ì—ëŸ¬: {e}")
            return None

    async def run_full_backtest(self, months_back: int = 12, test_period_months: int = 3) -> List[BacktestResult]:
        """ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰

        Args:
            months_back: ëª‡ ê°œì›” ì „ê¹Œì§€ ë°±í…ŒìŠ¤íŒ…í• ì§€
            test_period_months: ê° ì˜ˆì¸¡ì˜ í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ê°œì›”)

        Returns:
            List[BacktestResult]
        """
        logger.info(f"ğŸš€ ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì‹œì‘: ê³¼ê±° {months_back}ê°œì›”, í…ŒìŠ¤íŠ¸ ê¸°ê°„ {test_period_months}ê°œì›”")

        # 1. ì‹œì ë³„ ë¸”ë¡œê·¸ ë¶„í• 
        segments = self.segment_blogs_by_time(months_back)

        all_results = []

        # 2. ê° ì‹œì ë³„ë¡œ ë°±í…ŒìŠ¤íŒ…
        for month_key in sorted(segments.keys()):
            insights = segments[month_key]
            logger.info(f"\nğŸ“… {month_key} ë°±í…ŒìŠ¤íŒ… ({len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸)")

            # 3. ì¸ì‚¬ì´íŠ¸ì—ì„œ ì˜ˆì¸¡ ì¶”ì¶œ
            predictions = self.extract_predictions_from_insights(insights)
            logger.info(f"   ì¶”ì¶œëœ ì˜ˆì¸¡: {len(predictions)}ê°œ")

            # 4. ê° ì˜ˆì¸¡ ë°±í…ŒìŠ¤íŒ…
            for i, pred in enumerate(predictions[:50]):  # ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ 50ê°œë§Œ
                result = await self.backtest_insight(
                    insight=pred["insight"],
                    ticker=pred["ticker"],
                    direction=pred["direction"],
                    test_period_months=test_period_months
                )

                if result:
                    all_results.append(result)

                # ì§„í–‰ë¥  í‘œì‹œ
                if (i + 1) % 10 == 0:
                    logger.info(f"   ì§„í–‰ë¥ : {i+1}/{len(predictions[:50])}")

        logger.info(f"\nğŸ‰ ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì™„ë£Œ: {len(all_results)}ê°œ ê²°ê³¼")
        return all_results

    def analyze_backtest_results(self, results: List[BacktestResult]) -> Dict:
        """ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„ ë° í†µê³„"""
        if not results:
            return {"error": "ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ì—†ìŒ"}

        total = len(results)
        successful = sum(1 for r in results if r.success)
        success_rate = (successful / total) * 100

        avg_correlation = np.mean([r.correlation_score for r in results])

        # ì‹ ë¢°ë„ë³„ ì„±ê³µë¥ 
        high_confidence = [r for r in results if r.confidence_level == "ë†’ìŒ"]
        high_confidence_success_rate = (sum(1 for r in high_confidence if r.success) / len(high_confidence) * 100) if high_confidence else 0

        # í‚¤ì›Œë“œë³„ ì„±ê³µë¥ 
        keyword_stats = {}
        for result in results:
            for keyword in result.insight.keywords:
                if keyword not in keyword_stats:
                    keyword_stats[keyword] = {"total": 0, "success": 0}
                keyword_stats[keyword]["total"] += 1
                if result.success:
                    keyword_stats[keyword]["success"] += 1

        # ì„±ê³µë¥  ê³„ì‚°
        for keyword in keyword_stats:
            stats = keyword_stats[keyword]
            stats["success_rate"] = (stats["success"] / stats["total"]) * 100 if stats["total"] > 0 else 0

        # ìƒìœ„ í‚¤ì›Œë“œ (ì„±ê³µë¥  ë†’ì€ ìˆœ)
        top_keywords = sorted(
            keyword_stats.items(),
            key=lambda x: (x[1]["success_rate"], x[1]["total"]),
            reverse=True
        )[:10]

        return {
            "total_backtests": total,
            "successful": successful,
            "success_rate": round(success_rate, 2),
            "avg_correlation": round(avg_correlation, 4),
            "high_confidence_success_rate": round(high_confidence_success_rate, 2),
            "confidence_breakdown": {
                "ë†’ìŒ": len([r for r in results if r.confidence_level == "ë†’ìŒ"]),
                "ì¤‘ê°„": len([r for r in results if r.confidence_level == "ì¤‘ê°„"]),
                "ë‚®ìŒ": len([r for r in results if r.confidence_level == "ë‚®ìŒ"])
            },
            "top_keywords": [
                {"keyword": k, **v} for k, v in top_keywords
            ]
        }


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def main():
    """ë°±í…ŒìŠ¤í„° í…ŒìŠ¤íŠ¸"""
    backtester = BlogBacktester()

    # ì „ì²´ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ (ê³¼ê±° 6ê°œì›”, í…ŒìŠ¤íŠ¸ ê¸°ê°„ 3ê°œì›”)
    results = await backtester.run_full_backtest(months_back=6, test_period_months=3)

    # ê²°ê³¼ ë¶„ì„
    analysis = backtester.analyze_backtest_results(results)

    print("\n" + "="*60)
    print("ğŸ“Š ë¸”ë¡œê·¸ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë¶„ì„")
    print("="*60)
    print(json.dumps(analysis, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
