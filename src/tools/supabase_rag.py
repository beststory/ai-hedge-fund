"""Supabase pgvector ê¸°ë°˜ íˆ¬ì ì¸ì‚¬ì´íŠ¸ RAG ì‹œìŠ¤í…œ"""
import os
import json
import requests
from typing import List, Dict
import logging
from supabase import create_client, Client
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SupabaseRAG:
    """Supabase pgvector ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""

    def __init__(self):
        # Supabase ì„¤ì •
        self.supabase_url = os.getenv("SUPABASE_PUBLIC_URL", "http://localhost:8000")
        self.supabase_key = os.getenv("SERVICE_ROLE_KEY")
        self.ollama_url = "http://localhost:11434"

        if not self.supabase_key:
            raise ValueError("SERVICE_ROLE_KEY not found in .env")

        # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.client: Client = create_client(self.supabase_url, self.supabase_key)
            logger.info(f"âœ… Supabase ì—°ê²° ì„±ê³µ: {self.supabase_url}")
        except Exception as e:
            logger.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def generate_embedding(self, text: str) -> List[float]:
        """Ollama nomic-embed-text ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±"""
        try:
            response = requests.post(
                f"{self.ollama_url}/api/embeddings",
                json={
                    "model": "nomic-embed-text",
                    "prompt": text
                },
                timeout=30
            )
            response.raise_for_status()
            embedding = response.json()["embedding"]
            logger.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding)})")
            return embedding

        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def setup_database(self):
        """pgvector í™•ì¥ ë° í…Œì´ë¸” ìƒì„±"""
        try:
            # pgvector í™•ì¥ í™œì„±í™” (ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)
            logger.info("ğŸ”§ pgvector í™•ì¥ ì„¤ì • ì¤‘...")

            # investment_insights í…Œì´ë¸” ìƒì„±
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS investment_insights (
                id SERIAL PRIMARY KEY,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                sector TEXT,
                sentiment TEXT,
                keywords TEXT[],
                date TEXT,
                url TEXT,
                embedding vector(768),
                created_at TIMESTAMPTZ DEFAULT NOW()
            );

            -- ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (HNSW ì•Œê³ ë¦¬ì¦˜)
            CREATE INDEX IF NOT EXISTS investment_insights_embedding_idx
            ON investment_insights
            USING hnsw (embedding vector_cosine_ops);
            """

            # SupabaseëŠ” SQL ì‹¤í–‰ì„ REST APIë¡œ í•´ì•¼ í•¨
            # ëŒ€ì‹  ë°ì´í„° ì‚½ì…/ì¡°íšŒëŠ” Python í´ë¼ì´ì–¸íŠ¸ë¡œ ê°€ëŠ¥

            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")
            logger.info("âš ï¸  pgvector í™•ì¥ ë° í…Œì´ë¸”ì€ Supabase ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ìƒì„± í•„ìš”")
            logger.info(f"   SQL: \n{create_table_sql}")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise

    def insert_insight(self, insight: Dict) -> bool:
        """ì¸ì‚¬ì´íŠ¸ ì‚½ì…"""
        try:
            # ì œëª© + ë‚´ìš©ìœ¼ë¡œ ì„ë² ë”© ìƒì„±
            text = f"{insight['title']} {insight['content']}"
            embedding = self.generate_embedding(text)

            # Supabaseì— ì‚½ì…
            data = {
                "title": insight["title"],
                "content": insight["content"],
                "sector": insight.get("sector", ""),
                "sentiment": insight.get("sentiment", ""),
                "keywords": insight.get("keywords", []),
                "date": insight.get("date", ""),
                "url": insight.get("url", ""),
                "embedding": embedding
            }

            result = self.client.table("investment_insights").insert(data).execute()

            logger.info(f"âœ… ì¸ì‚¬ì´íŠ¸ ì‚½ì… ì™„ë£Œ: {insight['title'][:50]}...")
            return True

        except Exception as e:
            logger.error(f"âŒ ì¸ì‚¬ì´íŠ¸ ì‚½ì… ì‹¤íŒ¨: {e}")
            return False

    def search_similar(self, query: str, top_k: int = 3) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.generate_embedding(query)

            # pgvector ìœ ì‚¬ë„ ê²€ìƒ‰ (RPC í•¨ìˆ˜ í˜¸ì¶œ)
            # Supabaseì—ì„œ ì•„ë˜ í•¨ìˆ˜ë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ì•¼ í•¨:
            # CREATE FUNCTION match_insights(query_embedding vector(768), match_count int)
            # RETURNS TABLE (id int, title text, content text, sector text, sentiment text, keywords text[], similarity float)
            # AS $$
            #   SELECT id, title, content, sector, sentiment, keywords,
            #          1 - (embedding <=> query_embedding) as similarity
            #   FROM investment_insights
            #   ORDER BY embedding <=> query_embedding
            #   LIMIT match_count;
            # $$ LANGUAGE sql;

            result = self.client.rpc(
                "match_insights",
                {
                    "query_embedding": query_embedding,
                    "match_count": top_k
                }
            ).execute()

            insights = result.data
            logger.info(f"âœ… {len(insights)}ê°œ ìœ ì‚¬ ì¸ì‚¬ì´íŠ¸ ë°œê²¬")

            return insights

        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def migrate_json_data(self, json_path: str):
        """JSON ë°ì´í„°ë¥¼ Supabaseë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        try:
            logger.info(f"ğŸ“¦ JSON ë°ì´í„° ë¡œë“œ ì¤‘: {json_path}")

            with open(json_path, 'r', encoding='utf-8') as f:
                insights = json.load(f)

            logger.info(f"ğŸ“Š {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")

            success_count = 0
            for i, insight in enumerate(insights, 1):
                logger.info(f"[{i}/{len(insights)}] ì‚½ì… ì¤‘...")
                if self.insert_insight(insight):
                    success_count += 1

            logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {success_count}/{len(insights)} ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            raise


def test_supabase_rag():
    """Supabase RAG í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ§ª Supabase RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 80)

    try:
        # 1. Supabase ì—°ê²° í…ŒìŠ¤íŠ¸
        rag = SupabaseRAG()

        # 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        rag.setup_database()

        # 3. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
        logger.info("\n[í…ŒìŠ¤íŠ¸ 1] ì„ë² ë”© ìƒì„±")
        test_text = "ì–‘ìì»´í“¨íŒ… ê¸°ìˆ  ë°œì „ê³¼ íˆ¬ì ê¸°íšŒ"
        embedding = rag.generate_embedding(test_text)
        logger.info(f"  - í…ìŠ¤íŠ¸: {test_text}")
        logger.info(f"  - ì„ë² ë”© ì°¨ì›: {len(embedding)}")
        logger.info(f"  - ìƒ˜í”Œ: {embedding[:5]}")

        logger.info("\n" + "=" * 80)
        logger.info("âœ… Supabase RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info("=" * 80 + "\n")

        logger.info("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info("1. Supabase ëŒ€ì‹œë³´ë“œì—ì„œ pgvector í™•ì¥ í™œì„±í™”")
        logger.info("2. investment_insights í…Œì´ë¸” ë° match_insights í•¨ìˆ˜ ìƒì„±")
        logger.info("3. JSON ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰")

    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


if __name__ == '__main__':
    test_supabase_rag()
