"""ì „ì²´ ë¸”ë¡œê·¸ í¬ë¡¤ë§ (1800ê°œ) - ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ìš©"""
import sys
import logging
from src.tools.blog_crawler import NaverBlogCrawler

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/crawl_all_blogs.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

if __name__ == '__main__':
    blog_id = "ranto28"
    max_posts = 1877
    output_file = "data/blog_raw_all.json"

    logger.info(f"ğŸš€ ì „ì²´ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì‹œì‘: {blog_id}")
    logger.info(f"  - ìµœëŒ€ ê°œìˆ˜: {max_posts}ê°œ")
    logger.info(f"  - ì €ì¥ ê²½ë¡œ: {output_file}")

    crawler = NaverBlogCrawler(blog_id)

    try:
        posts = crawler.crawl_all(max_posts=max_posts, save_path=output_file)
        logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(posts)}ê°œ ìˆ˜ì§‘")
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    finally:
        crawler.close()
