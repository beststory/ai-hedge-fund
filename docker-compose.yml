services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      # Apple Silicon GPU acceleration
      - METAL_DEVICE=on
      - METAL_DEVICE_INDEX=0
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped

  hedge-fund:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  hedge-fund-reasoning:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  hedge-fund-ollama:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA --ollama
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  backtester:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/backtester.py --ticker AAPL,MSFT,NVDA
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  backtester-ollama:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  web-api:
    build: .
    image: ai-hedge-fund
    container_name: ai-hedge-fund-web
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
      - ./web:/app/web
      - ./data:/app/data
    command: python simple_web_api.py
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    ports:
      - "8888:8888"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  ollama_data: 